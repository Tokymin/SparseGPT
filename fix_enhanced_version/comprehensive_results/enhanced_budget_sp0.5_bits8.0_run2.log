运行增强版 SparseGPT (Budget方法, 目标8.0bit)...
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.k_proj] 时间: 3.64s | 误差: 13602.1074
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.v_proj] 时间: 3.58s | 误差: 533.1898
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.q_proj] 时间: 3.61s | 误差: 13788.3301
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.out_proj] 时间: 3.74s | 误差: 6.2849
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.fc1] 时间: 3.71s | 误差: 2199.3691
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer0.fc2] 时间: 14.69s | 误差: 34.3660
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.k_proj] 时间: 3.65s | 误差: 9457.8203
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.v_proj] 时间: 3.54s | 误差: 624.7678
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.q_proj] 时间: 3.63s | 误差: 3915.9805
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.out_proj] 时间: 3.69s | 误差: 3.9826
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.fc1] 时间: 3.67s | 误差: 6109.8926
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer1.fc2] 时间: 14.66s | 误差: 13.3628
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.k_proj] 时间: 3.63s | 误差: 15456.0469
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.v_proj] 时间: 3.64s | 误差: 1642.2532
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.q_proj] 时间: 3.50s | 误差: 13944.8496
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.out_proj] 时间: 3.66s | 误差: 9.4473
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.fc1] 时间: 3.62s | 误差: 4953.9448
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer2.fc2] 时间: 7.98s | 误差: 9.8826
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.k_proj] 时间: 0.51s | 误差: 14005.4346
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.v_proj] 时间: 0.51s | 误差: 2278.5962
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.q_proj] 时间: 0.49s | 误差: 14029.3994
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.out_proj] 时间: 0.51s | 误差: 15.9415
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.fc1] 时间: 0.49s | 误差: 3017.4946
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer3.fc2] 时间: 2.05s | 误差: 0.4524
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.k_proj] 时间: 0.50s | 误差: 26805.1465
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.v_proj] 时间: 0.51s | 误差: 3105.2373
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.q_proj] 时间: 0.50s | 误差: 28656.6270
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.out_proj] 时间: 0.50s | 误差: 24.2011
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.fc1] 时间: 0.53s | 误差: 7805.7690
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer4.fc2] 时间: 2.07s | 误差: 28.5005
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.k_proj] 时间: 0.50s | 误差: 29102.7227
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.v_proj] 时间: 0.52s | 误差: 2828.3154
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.q_proj] 时间: 0.50s | 误差: 34243.3594
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.out_proj] 时间: 0.51s | 误差: 38.7026
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.fc1] 时间: 0.52s | 误差: 7985.2603
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer5.fc2] 时间: 1.98s | 误差: 68.5127
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.k_proj] 时间: 0.49s | 误差: 31499.6328
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.v_proj] 时间: 0.50s | 误差: 3852.0137
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.q_proj] 时间: 0.50s | 误差: 33273.4453
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.out_proj] 时间: 0.49s | 误差: 49.2919
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.fc1] 时间: 0.49s | 误差: 7929.0430
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer6.fc2] 时间: 2.01s | 误差: 98.7505
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.k_proj] 时间: 0.50s | 误差: 38645.4727
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.v_proj] 时间: 0.50s | 误差: 4478.9707
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.q_proj] 时间: 0.49s | 误差: 38435.8281
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.out_proj] 时间: 0.50s | 误差: 83.7501
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.fc1] 时间: 0.68s | 误差: 10197.9375
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer7.fc2] 时间: 3.09s | 误差: 134.2201
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.k_proj] 时间: 0.50s | 误差: 39489.5547
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.v_proj] 时间: 0.50s | 误差: 6355.8760
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.q_proj] 时间: 0.50s | 误差: 44031.3359
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.out_proj] 时间: 0.50s | 误差: 157.8494
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.fc1] 时间: 0.50s | 误差: 14120.7012
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
[layer8.fc2] 时间: 1.98s | 误差: 220.3589
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.k_proj] 时间: 0.50s | 误差: 46396.7422
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.v_proj] 时间: 0.50s | 误差: 7485.9375
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.q_proj] 时间: 0.50s | 误差: 50355.9141
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.out_proj] 时间: 0.49s | 误差: 272.7380
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.fc1] 时间: 0.49s | 误差: 19369.9023
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer9.fc2] 时间: 1.98s | 误差: 360.5291
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.k_proj] 时间: 0.50s | 误差: 43848.1094
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.v_proj] 时间: 0.51s | 误差: 9339.0449
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.q_proj] 时间: 0.50s | 误差: 43050.2422
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.out_proj] 时间: 0.49s | 误差: 258.3690
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.fc1] 时间: 0.50s | 误差: 24412.2148
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer10.fc2] 时间: 1.97s | 误差: 551.9164
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.k_proj] 时间: 0.49s | 误差: 43246.8203
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.v_proj] 时间: 0.50s | 误差: 11645.5430
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.q_proj] 时间: 0.51s | 误差: 46050.4922
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.out_proj] 时间: 0.49s | 误差: 460.5126
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.fc1] 时间: 0.50s | 误差: 26936.2773
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer11.fc2] 时间: 2.04s | 误差: 579.4448

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  8-bit:  82944 通道 (100.00%)

平均比特数: 8.000 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 50.00% sparse
Layer model.decoder.layers.0.fc2.weight: 50.00% sparse
Total pruning time: 142.55s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 36.199
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 56.182
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 35.566
完成时间: 2025年 10月 13日 星期一 04:43:09 CST

