/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.k_proj] 时间: 0.43s | 误差: 13602.1084
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.v_proj] 时间: 0.32s | 误差: 533.1898
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.q_proj] 时间: 0.32s | 误差: 13788.3301
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.out_proj] 时间: 0.32s | 误差: 6.2849
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.fc1] 时间: 0.32s | 误差: 2199.3691
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer0.fc2] 时间: 1.28s | 误差: 34.3660
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.k_proj] 时间: 0.32s | 误差: 9457.8184
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.v_proj] 时间: 0.32s | 误差: 624.7382
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.q_proj] 时间: 0.32s | 误差: 3916.2251
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.out_proj] 时间: 0.32s | 误差: 3.9827
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.fc1] 时间: 0.32s | 误差: 6110.0010
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer1.fc2] 时间: 1.28s | 误差: 13.3630
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.k_proj] 时间: 0.32s | 误差: 15454.3047
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.v_proj] 时间: 0.32s | 误差: 1642.2051
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.q_proj] 时间: 0.32s | 误差: 13944.0781
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.out_proj] 时间: 0.32s | 误差: 9.4486
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.fc1] 时间: 0.32s | 误差: 4953.8906
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer2.fc2] 时间: 1.28s | 误差: 9.8828
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.k_proj] 时间: 0.60s | 误差: 14004.5918
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.v_proj] 时间: 2.99s | 误差: 2278.7512
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.q_proj] 时间: 4.87s | 误差: 14028.5234
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.out_proj] 时间: 4.91s | 误差: 15.9413
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.fc1] 时间: 4.96s | 误差: 3017.3701
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 4bit(1843通道) 6bit(614通道) 8bit(615通道) | 平均: 5.20 bits
[layer3.fc2] 时间: 19.52s | 误差: 0.4526
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.k_proj] 时间: 4.93s | 误差: 26797.2051
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.v_proj] 时间: 4.90s | 误差: 3105.8979
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.q_proj] 时间: 4.83s | 误差: 28656.3613
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.out_proj] 时间: 4.93s | 误差: 24.1864
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.fc1] 时间: 4.96s | 误差: 7804.1895
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer4.fc2] 时间: 21.87s | 误差: 28.4980
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.k_proj] 时间: 4.90s | 误差: 29113.2461
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.v_proj] 时间: 4.91s | 误差: 2829.5273
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.q_proj] 时间: 4.94s | 误差: 34229.6836
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.out_proj] 时间: 4.89s | 误差: 38.6216
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.fc1] 时间: 4.94s | 误差: 7985.2441
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer5.fc2] 时间: 24.88s | 误差: 68.4317
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.k_proj] 时间: 4.92s | 误差: 31473.3926
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.v_proj] 时间: 4.95s | 误差: 3851.2947
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.q_proj] 时间: 4.97s | 误差: 33285.3125
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.out_proj] 时间: 4.89s | 误差: 49.2800
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.fc1] 时间: 4.97s | 误差: 7929.6953
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer6.fc2] 时间: 21.98s | 误差: 98.4973
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.k_proj] 时间: 4.92s | 误差: 38630.2109
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.v_proj] 时间: 4.95s | 误差: 4477.0728
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.q_proj] 时间: 4.94s | 误差: 38444.4961
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.out_proj] 时间: 4.90s | 误差: 83.8105
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.fc1] 时间: 4.95s | 误差: 10189.0078
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer7.fc2] 时间: 24.90s | 误差: 134.1205
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.k_proj] 时间: 4.93s | 误差: 39453.0703
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.v_proj] 时间: 4.95s | 误差: 6350.5913
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.q_proj] 时间: 4.94s | 误差: 44008.7969
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.out_proj] 时间: 4.94s | 误差: 157.9515
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.fc1] 时间: 4.91s | 误差: 14115.1133
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer8.fc2] 时间: 22.00s | 误差: 220.6349
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.k_proj] 时间: 4.94s | 误差: 46377.4297
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.v_proj] 时间: 4.92s | 误差: 7484.5225
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.q_proj] 时间: 4.94s | 误差: 50306.7852
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.out_proj] 时间: 4.94s | 误差: 274.6578
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.fc1] 时间: 5.66s | 误差: 19357.1777
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer9.fc2] 时间: 24.08s | 误差: 359.8978
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.k_proj] 时间: 4.92s | 误差: 43843.6719
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.v_proj] 时间: 4.93s | 误差: 9335.6885
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.q_proj] 时间: 4.91s | 误差: 43062.5352
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.out_proj] 时间: 4.92s | 误差: 259.2320
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.fc1] 时间: 5.12s | 误差: 24424.1602
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer10.fc2] 时间: 21.86s | 误差: 551.3635
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.k_proj] 时间: 4.94s | 误差: 43214.5000
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.v_proj] 时间: 4.95s | 误差: 11626.2539
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.q_proj] 时间: 4.96s | 误差: 46014.4766
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.out_proj] 时间: 4.91s | 误差: 462.2870
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.fc1] 时间: 5.72s | 误差: 26914.1660
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer11.fc2] 时间: 24.12s | 误差: 578.4911

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  16005 通道 (19.30%)
  3-bit:  15934 通道 (19.21%)
  4-bit:  17837 通道 (21.50%)
  6-bit:  16548 通道 (19.95%)
  8-bit:  16620 通道 (20.04%)

平均比特数: 4.609 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 50.00% sparse
Layer model.decoder.layers.0.fc2.weight: 50.00% sparse
Total pruning time: 444.81s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 36.186
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 56.294
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 35.601
