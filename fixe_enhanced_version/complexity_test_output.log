========================================================================
计算复杂度对比测试
========================================================================

========================================================================
测试方法: original
========================================================================
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Starting ...
Ready.
0 self_attn.k_proj
Pruning ...
time 0.92
error 20929.4140625
0 self_attn.v_proj
Pruning ...
time 0.46
error 652.8306884765625
0 self_attn.q_proj
Pruning ...
time 0.45
error 20076.3828125
0 self_attn.out_proj
Pruning ...
time 0.69
error 10.524332046508789
0 fc1
Pruning ...
time 0.66
error 2588.833984375
0 fc2
Pruning ...
time 2.75
error 59.86692810058594
1 self_attn.k_proj
Pruning ...
time 0.67
error 14204.203125
1 self_attn.v_proj
Pruning ...
time 0.71
error 758.90283203125
1 self_attn.q_proj
Pruning ...
time 0.45
error 7552.2109375
1 self_attn.out_proj
Pruning ...
time 0.66
error 8.416763305664062
1 fc1
Pruning ...
time 0.70
error 8520.7578125
1 fc2
Pruning ...
time 2.75
error 39.05036544799805
2 self_attn.k_proj
Pruning ...
time 0.52
error 29435.169921875
2 self_attn.v_proj
Pruning ...
time 0.81
error 2159.138916015625
2 self_attn.q_proj
Pruning ...
time 0.48
error 24904.740234375
2 self_attn.out_proj
Pruning ...
time 0.45
error 13.396286964416504
2 fc1
Pruning ...
time 0.67
error 7604.3681640625
2 fc2
Pruning ...
time 2.99
error 35.310752868652344
3 self_attn.k_proj
Pruning ...
time 0.45
error 23900.431640625
3 self_attn.v_proj
Pruning ...
time 0.68
error 2960.34326171875
3 self_attn.q_proj
Pruning ...
time 0.68
error 22721.322265625
3 self_attn.out_proj
Pruning ...
time 0.45
error 18.79778289794922
3 fc1
Pruning ...
time 0.67
error 4914.51806640625
3 fc2
Pruning ...
time 2.99
error 22.388044357299805
4 self_attn.k_proj
Pruning ...
time 0.46
error 38607.62890625
4 self_attn.v_proj
Pruning ...
time 0.67
error 3868.364501953125
4 self_attn.q_proj
Pruning ...
time 0.69
error 40259.390625
4 self_attn.out_proj
Pruning ...
time 0.45
error 30.438142776489258
4 fc1
Pruning ...
time 0.66
error 10291.8447265625
4 fc2
Pruning ...
time 2.99
error 77.31851196289062
5 self_attn.k_proj
Pruning ...
time 0.45
error 41082.3671875
5 self_attn.v_proj
Pruning ...
time 0.67
error 3465.33154296875
5 self_attn.q_proj
Pruning ...
time 0.70
error 45656.296875
5 self_attn.out_proj
Pruning ...
time 0.45
error 54.87929153442383
5 fc1
Pruning ...
time 0.58
error 9715.6767578125
5 fc2
Pruning ...
time 2.83
error 153.79794311523438
6 self_attn.k_proj
Pruning ...
time 0.45
error 44027.23046875
6 self_attn.v_proj
Pruning ...
time 0.48
error 4705.41259765625
6 self_attn.q_proj
Pruning ...
time 0.80
error 45146.65625
6 self_attn.out_proj
Pruning ...
time 0.53
error 60.518646240234375
6 fc1
Pruning ...
time 0.45
error 9624.95703125
6 fc2
Pruning ...
time 2.96
error 201.44686889648438
7 self_attn.k_proj
Pruning ...
time 0.48
error 50976.4375
7 self_attn.v_proj
Pruning ...
time 0.46
error 5366.375
7 self_attn.q_proj
Pruning ...
time 0.81
error 50857.8515625
7 self_attn.out_proj
Pruning ...
time 0.54
error 100.53565979003906
7 fc1
Pruning ...
time 0.45
error 12162.1240234375
7 fc2
Pruning ...
time 2.97
error 253.63729858398438
8 self_attn.k_proj
Pruning ...
time 0.61
error 51530.046875
8 self_attn.v_proj
Pruning ...
time 0.46
error 7585.64453125
8 self_attn.q_proj
Pruning ...
time 0.66
error 56044.40625
8 self_attn.out_proj
Pruning ...
time 0.69
error 164.07644653320312
8 fc1
Pruning ...
time 0.45
error 16398.91796875
8 fc2
Pruning ...
time 2.88
error 413.7518310546875
9 self_attn.k_proj
Pruning ...
time 0.70
error 58986.77734375
9 self_attn.v_proj
Pruning ...
time 0.46
error 8850.91015625
9 self_attn.q_proj
Pruning ...
time 0.66
error 62135.9609375
9 self_attn.out_proj
Pruning ...
time 0.70
error 274.404296875
9 fc1
Pruning ...
time 0.45
error 22120.2890625
9 fc2
Pruning ...
time 2.79
error 581.360595703125
10 self_attn.k_proj
Pruning ...
time 0.70
error 57000.62890625
10 self_attn.v_proj
Pruning ...
time 0.46
error 10879.10546875
10 self_attn.q_proj
Pruning ...
time 0.62
error 55152.6875
10 self_attn.out_proj
Pruning ...
time 0.72
error 344.3186340332031
10 fc1
Pruning ...
time 0.45
error 27649.02734375
10 fc2
Pruning ...
time 1.80
error 938.9923706054688
11 self_attn.k_proj
Pruning ...
time 0.53
error 53823.6953125
11 self_attn.v_proj
Pruning ...
time 0.29
error 13507.134765625
11 self_attn.q_proj
Pruning ...
time 0.36
error 55543.0234375
11 self_attn.out_proj
Pruning ...
time 0.57
error 543.1163330078125
11 fc1
Pruning ...
time 0.38
error 31609.41015625
11 fc2
Pruning ...
time 1.60
error 1171.0069580078125
model.decoder.embed_tokens.weight tensor(3.8851e-07)
model.decoder.embed_positions.weight tensor(0.0005)
model.decoder.final_layer_norm.weight tensor(0.)
model.decoder.final_layer_norm.bias tensor(0.)
model.decoder.layers.0.self_attn.k_proj.weight tensor(0.5027)
model.decoder.layers.0.self_attn.k_proj.bias tensor(0.)
model.decoder.layers.0.self_attn.v_proj.weight tensor(0.5018)
model.decoder.layers.0.self_attn.v_proj.bias tensor(0.)
model.decoder.layers.0.self_attn.q_proj.weight tensor(0.5017)
model.decoder.layers.0.self_attn.q_proj.bias tensor(0.)
model.decoder.layers.0.self_attn.out_proj.weight tensor(0.5083)
model.decoder.layers.0.self_attn.out_proj.bias tensor(0.)
model.decoder.layers.0.self_attn_layer_norm.weight tensor(0.)
model.decoder.layers.0.self_attn_layer_norm.bias tensor(0.)
model.decoder.layers.0.fc1.weight tensor(0.5010)
model.decoder.layers.0.fc1.bias tensor(0.)
model.decoder.layers.0.fc2.weight tensor(0.5084)
76.93824768066406
wikitext2
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
Perplexity: 39.108929
ptb
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
Perplexity: 60.309185
c4
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
Perplexity: 37.436649
	Command being timed: "/media/user/data3/toky/CondaEnvs/SparseGPT/bin/python opt.py facebook/opt-125m c4 --sparsity 0.5 --wbits 4"
	User time (seconds): 140.71
	System time (seconds): 22.63
	Percent of CPU this job got: 101%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 2:40.94
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 1242536
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 1117140
	Voluntary context switches: 4075
	Involuntary context switches: 1186
	Swaps: 0
	File system inputs: 0
	File system outputs: 16
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0

总运行时间: 161 秒

性能指标:
  总时间: 161 秒
  峰值内存: 1213.41 MB
  平均每层时间: 161 秒
  吞吐量: .795 samples/sec

========================================================================
测试方法: enhanced_quantile
========================================================================
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.k_proj] 时间: 1.89s | 误差: 13602.1084
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.v_proj] 时间: 1.76s | 误差: 533.1898
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.q_proj] 时间: 2.24s | 误差: 13788.3301
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.out_proj] 时间: 1.72s | 误差: 6.2849
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.fc1] 时间: 1.56s | 误差: 2199.3691
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer0.fc2] 时间: 7.75s | 误差: 34.3660
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.k_proj] 时间: 1.66s | 误差: 9457.8184
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.v_proj] 时间: 1.64s | 误差: 624.7382
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.q_proj] 时间: 2.22s | 误差: 3916.2251
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.out_proj] 时间: 1.76s | 误差: 3.9827
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.fc1] 时间: 1.76s | 误差: 6110.0010
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer1.fc2] 时间: 7.47s | 误差: 13.3630
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.k_proj] 时间: 2.24s | 误差: 15454.3047
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.v_proj] 时间: 1.76s | 误差: 1642.2051
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.q_proj] 时间: 1.51s | 误差: 13944.0781
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.out_proj] 时间: 2.23s | 误差: 9.4486
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.fc1] 时间: 1.73s | 误差: 4953.8906
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer2.fc2] 时间: 7.29s | 误差: 9.8828
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.k_proj] 时间: 2.24s | 误差: 14004.5918
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.v_proj] 时间: 1.75s | 误差: 2278.7512
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.q_proj] 时间: 1.76s | 误差: 14028.5234
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.out_proj] 时间: 2.24s | 误差: 15.9413
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.fc1] 时间: 1.75s | 误差: 3017.3701
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 4bit(1843通道) 6bit(614通道) 8bit(615通道) | 平均: 5.20 bits
[layer3.fc2] 时间: 5.49s | 误差: 0.4526
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.k_proj] 时间: 1.15s | 误差: 26797.2051
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.v_proj] 时间: 1.13s | 误差: 3105.8979
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.q_proj] 时间: 1.24s | 误差: 28656.3613
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.out_proj] 时间: 1.24s | 误差: 24.1864
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.fc1] 时间: 1.24s | 误差: 7804.1895
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer4.fc2] 时间: 6.62s | 误差: 28.4980
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.k_proj] 时间: 1.10s | 误差: 29113.2461
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.v_proj] 时间: 1.17s | 误差: 2829.5273
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.q_proj] 时间: 1.24s | 误差: 34229.6836
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.out_proj] 时间: 1.24s | 误差: 38.6216
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.fc1] 时间: 1.24s | 误差: 7985.2441
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer5.fc2] 时间: 4.54s | 误差: 68.4317
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.k_proj] 时间: 1.12s | 误差: 31473.3926
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.v_proj] 时间: 1.16s | 误差: 3851.2947
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.q_proj] 时间: 1.24s | 误差: 33285.3125
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.out_proj] 时间: 1.24s | 误差: 49.2800
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.fc1] 时间: 1.24s | 误差: 7929.6953
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer6.fc2] 时间: 4.55s | 误差: 98.4973
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.k_proj] 时间: 1.16s | 误差: 38630.2109
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.v_proj] 时间: 1.13s | 误差: 4477.0728
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.q_proj] 时间: 1.24s | 误差: 38444.4961
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.out_proj] 时间: 1.24s | 误差: 83.8105
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.fc1] 时间: 1.24s | 误差: 10189.0078
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer7.fc2] 时间: 5.28s | 误差: 134.1205
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.k_proj] 时间: 1.13s | 误差: 39453.0703
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.v_proj] 时间: 1.16s | 误差: 6350.5913
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.q_proj] 时间: 1.24s | 误差: 44008.7969
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.out_proj] 时间: 1.24s | 误差: 157.9515
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.fc1] 时间: 1.05s | 误差: 14115.1133
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer8.fc2] 时间: 8.38s | 误差: 220.6349
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.k_proj] 时间: 1.24s | 误差: 46377.4297
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.v_proj] 时间: 1.24s | 误差: 7484.5225
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.q_proj] 时间: 1.24s | 误差: 50306.7852
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.out_proj] 时间: 1.01s | 误差: 274.6578
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.fc1] 时间: 1.23s | 误差: 19357.1777
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer9.fc2] 时间: 4.75s | 误差: 359.8978
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.k_proj] 时间: 1.24s | 误差: 43843.6719
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.v_proj] 时间: 1.24s | 误差: 9335.6885
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.q_proj] 时间: 1.24s | 误差: 43062.5352
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.out_proj] 时间: 1.01s | 误差: 259.2320
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.fc1] 时间: 1.24s | 误差: 24424.1602
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer10.fc2] 时间: 6.49s | 误差: 551.3635
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.k_proj] 时间: 2.23s | 误差: 43214.5000
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.v_proj] 时间: 1.75s | 误差: 11626.2539
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.q_proj] 时间: 1.76s | 误差: 46014.4766
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.out_proj] 时间: 2.25s | 误差: 462.2870
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.fc1] 时间: 1.75s | 误差: 26914.1660
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer11.fc2] 时间: 7.24s | 误差: 578.4911

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  16005 通道 (19.30%)
  3-bit:  15934 通道 (19.21%)
  4-bit:  17837 通道 (21.50%)
  6-bit:  16548 通道 (19.95%)
  8-bit:  16620 通道 (20.04%)

平均比特数: 4.609 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 50.00% sparse
Layer model.decoder.layers.0.fc2.weight: 50.00% sparse
Total pruning time: 176.14s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 36.186
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 56.294
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 35.601
	Command being timed: "/media/user/data3/toky/CondaEnvs/SparseGPT/bin/python enhanced_version/opt_enhanced.py facebook/opt-125m c4 --sparsity 0.5 --wbits 4 --target_avg_bits 4.0 --bit_method quantile"
	User time (seconds): 240.67
	System time (seconds): 21.39
	Percent of CPU this job got: 98%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 4:24.81
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 1311116
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 1149292
	Voluntary context switches: 5249
	Involuntary context switches: 1303
	Swaps: 0
	File system inputs: 0
	File system outputs: 16
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0

总运行时间: 265 秒

性能指标:
  总时间: 265 秒
  峰值内存: 1280.38 MB
  平均每层时间: 3.63014 秒
  吞吐量: .483 samples/sec

========================================================================
测试方法: enhanced_budget
========================================================================
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.k_proj] 时间: 1.83s | 误差: 13602.1074
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.v_proj] 时间: 2.13s | 误差: 533.1898
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.q_proj] 时间: 2.20s | 误差: 13788.3301
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.out_proj] 时间: 3.86s | 误差: 6.2849
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.fc1] 时间: 4.92s | 误差: 2199.3340
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer0.fc2] 时间: 8.86s | 误差: 34.3660
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.k_proj] 时间: 2.19s | 误差: 9456.9277
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.v_proj] 时间: 2.21s | 误差: 624.7369
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.q_proj] 时间: 3.38s | 误差: 3916.2834
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.out_proj] 时间: 3.56s | 误差: 3.9823
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.fc1] 时间: 4.06s | 误差: 6109.9453
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer1.fc2] 时间: 15.71s | 误差: 13.3632
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.k_proj] 时间: 4.06s | 误差: 15455.2334
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.v_proj] 时间: 3.54s | 误差: 1641.6998
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.q_proj] 时间: 3.91s | 误差: 13944.4561
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.out_proj] 时间: 4.17s | 误差: 9.4491
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.fc1] 时间: 3.51s | 误差: 4954.1455
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer2.fc2] 时间: 15.56s | 误差: 9.8810
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.k_proj] 时间: 3.89s | 误差: 14012.7822
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.v_proj] 时间: 3.48s | 误差: 2278.8799
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.q_proj] 时间: 2.70s | 误差: 14031.4805
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.out_proj] 时间: 2.33s | 误差: 16.0174
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.fc1] 时间: 2.13s | 误差: 3019.6965
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer3.fc2] 时间: 10.92s | 误差: 0.4516
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.k_proj] 时间: 2.17s | 误差: 26812.3027
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.v_proj] 时间: 2.34s | 误差: 3107.6069
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.q_proj] 时间: 2.15s | 误差: 28663.3340
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.out_proj] 时间: 2.17s | 误差: 24.2370
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.fc1] 时间: 2.34s | 误差: 7806.0625
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer4.fc2] 时间: 9.10s | 误差: 28.5118
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.k_proj] 时间: 2.28s | 误差: 29111.7090
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.v_proj] 时间: 2.06s | 误差: 2831.0376
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.q_proj] 时间: 2.31s | 误差: 34242.1016
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.out_proj] 时间: 2.38s | 误差: 38.6558
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.fc1] 时间: 2.11s | 误差: 7987.1572
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer5.fc2] 时间: 9.92s | 误差: 68.4077
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.k_proj] 时间: 2.16s | 误差: 31462.5840
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.v_proj] 时间: 5.49s | 误差: 3854.2559
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.q_proj] 时间: 3.17s | 误差: 33278.5234
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.out_proj] 时间: 2.17s | 误差: 49.2530
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.fc1] 时间: 2.28s | 误差: 7926.5576
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer6.fc2] 时间: 9.04s | 误差: 98.5877
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.k_proj] 时间: 2.35s | 误差: 38650.4531
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.v_proj] 时间: 2.69s | 误差: 4478.6221
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.q_proj] 时间: 3.40s | 误差: 38451.0195
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.out_proj] 时间: 4.01s | 误差: 83.6418
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.fc1] 时间: 3.61s | 误差: 10194.2471
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer7.fc2] 时间: 15.56s | 误差: 134.0808
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.k_proj] 时间: 4.04s | 误差: 39452.6406
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.v_proj] 时间: 4.05s | 误差: 6353.2754
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.q_proj] 时间: 3.56s | 误差: 44013.7188
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.out_proj] 时间: 4.03s | 误差: 157.3816
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.fc1] 时间: 4.05s | 误差: 14120.0117
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer8.fc2] 时间: 14.95s | 误差: 220.6047
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.k_proj] 时间: 4.03s | 误差: 46350.3086
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.v_proj] 时间: 3.51s | 误差: 7487.8730
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.q_proj] 时间: 2.20s | 误差: 50324.3711
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.out_proj] 时间: 0.39s | 误差: 273.0558
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.fc1] 时间: 0.39s | 误差: 19360.0469
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer9.fc2] 时间: 1.56s | 误差: 360.5228
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.k_proj] 时间: 0.39s | 误差: 43853.8359
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.v_proj] 时间: 0.39s | 误差: 9329.6875
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.q_proj] 时间: 0.39s | 误差: 43040.7344
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.out_proj] 时间: 0.39s | 误差: 257.7951
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.fc1] 时间: 0.39s | 误差: 24402.1895
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer10.fc2] 时间: 1.56s | 误差: 551.1313
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.k_proj] 时间: 0.39s | 误差: 43191.3359
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.v_proj] 时间: 2.57s | 误差: 11612.2969
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.q_proj] 时间: 0.39s | 误差: 45986.2812
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.out_proj] 时间: 0.39s | 误差: 462.1172
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.fc1] 时间: 0.39s | 误差: 26881.0430
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer11.fc2] 时间: 1.56s | 误差: 577.0457

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  55296 通道 (66.67%)
  8-bit:  27648 通道 (33.33%)

平均比特数: 4.000 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 50.00% sparse
Layer model.decoder.layers.0.fc2.weight: 50.00% sparse
Total pruning time: 278.60s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 36.175
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 55.930
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 35.615
	Command being timed: "/media/user/data3/toky/CondaEnvs/SparseGPT/bin/python enhanced_version/opt_enhanced.py facebook/opt-125m c4 --sparsity 0.5 --wbits 4 --target_avg_bits 4.0 --bit_method budget"
	User time (seconds): 339.13
	System time (seconds): 20.38
	Percent of CPU this job got: 100%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 5:58.70
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 1429432
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 1281166
	Voluntary context switches: 6106
	Involuntary context switches: 1524
	Swaps: 0
	File system inputs: 0
	File system outputs: 16
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0

总运行时间: 359 秒

性能指标:
  总时间: 359 秒
  峰值内存: 1395.92 MB
  平均每层时间: 4.91781 秒
  吞吐量: .356 samples/sec

========================================================================
复杂度对比完成！
结果保存在: /media/user/data3/toky/Projects/SparseGPT/fixe_enhanced_version/complexity_results/complexity_benchmark.csv
========================================================================

对比摘要:
------------------------------------------------------------------------
method             wall_time_sec  gpu_memory_mb  layer_avg_time_sec  total_samples  throughput_samples_per_sec
original           161            1213.41        161                 128            .795
enhanced_quantile  265            1280.38        3.63014             128            .483
enhanced_budget    359            1395.92        4.91781             128            .356
------------------------------------------------------------------------


================================================================================
计算复杂度分析
================================================================================

基准方法 (original):
  时间: 161.00 秒
  内存: 1213.41 MB
  吞吐量: 0.795 samples/sec

改进方法对比:

enhanced_quantile:
  时间: 265.00 秒 (1.65x 基准)
  内存: 1280.38 MB (1.06x 基准)
  吞吐量: 0.483 samples/sec (0.61x 基准)
  ✗ 时间开销较大 (>1.5x)

enhanced_budget:
  时间: 359.00 秒 (2.23x 基准)
  内存: 1395.92 MB (1.15x 基准)
  吞吐量: 0.356 samples/sec (0.45x 基准)
  ✗ 时间开销较大 (>1.5x)

================================================================================
