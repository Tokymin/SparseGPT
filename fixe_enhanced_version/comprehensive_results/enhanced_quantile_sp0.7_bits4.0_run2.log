运行增强版 SparseGPT (Quantile方法, 目标4.0bit)...
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.k_proj] 时间: 1.41s | 误差: 54305.2070
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.v_proj] 时间: 1.35s | 误差: 1761.9504
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.q_proj] 时间: 1.22s | 误差: 53373.2461
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.out_proj] 时间: 1.21s | 误差: 22.5923
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.fc1] 时间: 1.35s | 误差: 7312.2974
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer0.fc2] 时间: 4.96s | 误差: 114.5998
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.k_proj] 时间: 1.16s | 误差: 40943.3125
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.v_proj] 时间: 1.26s | 误差: 2109.5503
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.q_proj] 时间: 1.35s | 误差: 18085.5801
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.out_proj] 时间: 1.17s | 误差: 15.5549
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.fc1] 时间: 1.26s | 误差: 20654.6016
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer1.fc2] 时间: 5.12s | 误差: 47.3804
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.k_proj] 时间: 1.35s | 误差: 59837.8438
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.v_proj] 时间: 1.21s | 误差: 5203.6924
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.q_proj] 时间: 1.22s | 误差: 53444.1016
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.out_proj] 时间: 1.34s | 误差: 29.2547
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.fc1] 时间: 1.22s | 误差: 17011.3203
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer2.fc2] 时间: 4.98s | 误差: 49.1147
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.k_proj] 时间: 1.21s | 误差: 54144.0898
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.v_proj] 时间: 1.35s | 误差: 6858.0190
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.q_proj] 时间: 1.22s | 误差: 52730.5469
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.out_proj] 时间: 1.27s | 误差: 36.6186
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.fc1] 时间: 1.29s | 误差: 10652.0820
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 4bit(1843通道) 6bit(614通道) 8bit(615通道) | 平均: 5.20 bits
[layer3.fc2] 时间: 5.03s | 误差: 11.6984
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.k_proj] 时间: 1.35s | 误差: 86181.1250
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.v_proj] 时间: 1.14s | 误差: 8925.5068
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.q_proj] 时间: 1.29s | 误差: 91340.3906
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.out_proj] 时间: 1.35s | 误差: 69.1396
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.fc1] 时间: 1.16s | 误差: 23655.0234
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer4.fc2] 时间: 5.04s | 误差: 92.7744
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.k_proj] 时间: 1.21s | 误差: 90524.9375
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.v_proj] 时间: 1.35s | 误差: 7953.8477
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.q_proj] 时间: 1.21s | 误差: 104210.7031
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.out_proj] 时间: 1.21s | 误差: 101.1748
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.fc1] 时间: 1.35s | 误差: 22690.4414
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer5.fc2] 时间: 4.91s | 误差: 178.7172
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.k_proj] 时间: 1.18s | 误差: 93578.8281
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.v_proj] 时间: 1.26s | 误差: 10310.7480
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.q_proj] 时间: 1.33s | 误差: 97872.7188
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.out_proj] 时间: 1.15s | 误差: 135.7420
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.fc1] 时间: 1.29s | 误差: 21564.4609
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer6.fc2] 时间: 5.07s | 误差: 199.7853
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.k_proj] 时间: 1.35s | 误差: 108145.6406
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.v_proj] 时间: 1.17s | 误差: 11501.8145
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.q_proj] 时间: 1.26s | 误差: 107294.5938
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.out_proj] 时间: 1.35s | 误差: 187.9825
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.fc1] 时间: 1.15s | 误差: 26401.8125
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer7.fc2] 时间: 5.05s | 误差: 192.7759
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.k_proj] 时间: 1.21s | 误差: 106095.5156
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.v_proj] 时间: 1.35s | 误差: 15925.2793
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.q_proj] 时间: 1.21s | 误差: 118655.3047
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.out_proj] 时间: 1.21s | 误差: 439.5852
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.fc1] 时间: 1.35s | 误差: 35518.8594
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer8.fc2] 时间: 5.05s | 误差: 279.6978
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.k_proj] 时间: 1.35s | 误差: 117959.7500
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.v_proj] 时间: 1.16s | 误差: 18209.3145
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.q_proj] 时间: 1.27s | 误差: 129425.1719
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.out_proj] 时间: 1.35s | 误差: 1031.8519
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.fc1] 时间: 1.10s | 误差: 47789.1758
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer9.fc2] 时间: 5.09s | 误差: 457.9821
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.k_proj] 时间: 1.21s | 误差: 108561.8281
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.v_proj] 时间: 1.35s | 误差: 22236.5781
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.q_proj] 时间: 1.30s | 误差: 105856.6484
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.out_proj] 时间: 1.15s | 误差: 539.4720
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.fc1] 时间: 1.33s | 误差: 58651.2383
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer10.fc2] 时间: 4.99s | 误差: 712.0965
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.k_proj] 时间: 1.22s | 误差: 103967.0078
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.v_proj] 时间: 1.21s | 误差: 27358.1250
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.q_proj] 时间: 1.35s | 误差: 111973.3672
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.out_proj] 时间: 1.23s | 误差: 1799.4001
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.fc1] 时间: 1.22s | 误差: 57214.1484
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer11.fc2] 时间: 5.11s | 误差: 812.2397

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  16005 通道 (19.30%)
  3-bit:  15934 通道 (19.21%)
  4-bit:  17837 通道 (21.50%)
  6-bit:  16548 通道 (19.95%)
  8-bit:  16620 通道 (20.04%)

平均比特数: 4.609 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 70.00% sparse
Layer model.decoder.layers.0.fc2.weight: 70.00% sparse
Total pruning time: 146.84s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 219.456
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 266.894
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 167.404
完成时间: 2025年 10月 13日 星期一 01:26:22 CST

