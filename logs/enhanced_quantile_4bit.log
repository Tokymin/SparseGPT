/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...
[layer0.self_attn.k_proj] 时间: 0.25s | 误差: 13602.1035
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...
[layer0.self_attn.v_proj] 时间: 0.10s | 误差: 533.1897
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...
[layer0.self_attn.q_proj] 时间: 0.11s | 误差: 13788.3271
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...
[layer0.self_attn.out_proj] 时间: 0.10s | 误差: 6.2850
Processing layer 0, component fc1
Pruning with SparseGPT ...
[layer0.fc1] 时间: 0.10s | 误差: 2199.3730
Processing layer 0, component fc2
Pruning with SparseGPT ...
[layer0.fc2] 时间: 0.40s | 误差: 34.3660
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...
[layer1.self_attn.k_proj] 时间: 0.15s | 误差: 9456.1514
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...
[layer1.self_attn.v_proj] 时间: 0.11s | 误差: 624.7892
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...
[layer1.self_attn.q_proj] 时间: 0.11s | 误差: 3916.4360
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...
[layer1.self_attn.out_proj] 时间: 0.11s | 误差: 3.9829
Processing layer 1, component fc1
Pruning with SparseGPT ...
[layer1.fc1] 时间: 0.11s | 误差: 6109.9463
Processing layer 1, component fc2
Pruning with SparseGPT ...
[layer1.fc2] 时间: 0.39s | 误差: 13.3636
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...
[layer2.self_attn.k_proj] 时间: 0.15s | 误差: 15456.1348
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...
[layer2.self_attn.v_proj] 时间: 0.10s | 误差: 1641.7578
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...
[layer2.self_attn.q_proj] 时间: 0.11s | 误差: 13941.3643
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...
[layer2.self_attn.out_proj] 时间: 0.11s | 误差: 9.4474
Processing layer 2, component fc1
Pruning with SparseGPT ...
[layer2.fc1] 时间: 0.11s | 误差: 4954.3975
Processing layer 2, component fc2
Pruning with SparseGPT ...
[layer2.fc2] 时间: 0.40s | 误差: 9.8785
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...
[layer3.self_attn.k_proj] 时间: 0.16s | 误差: 14009.1992
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...
[layer3.self_attn.v_proj] 时间: 0.10s | 误差: 2278.9873
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...
[layer3.self_attn.q_proj] 时间: 0.10s | 误差: 14030.1064
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...
[layer3.self_attn.out_proj] 时间: 0.11s | 误差: 15.9371
Processing layer 3, component fc1
Pruning with SparseGPT ...
[layer3.fc1] 时间: 0.10s | 误差: 3016.8193
Processing layer 3, component fc2
Pruning with SparseGPT ...
[layer3.fc2] 时间: 0.40s | 误差: 0.4525
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...
[layer4.self_attn.k_proj] 时间: 0.15s | 误差: 26804.4766
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...
[layer4.self_attn.v_proj] 时间: 0.10s | 误差: 3105.5898
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...
[layer4.self_attn.q_proj] 时间: 0.10s | 误差: 28660.6523
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...
[layer4.self_attn.out_proj] 时间: 0.10s | 误差: 24.2118
Processing layer 4, component fc1
Pruning with SparseGPT ...
[layer4.fc1] 时间: 0.10s | 误差: 7804.7031
Processing layer 4, component fc2
Pruning with SparseGPT ...
[layer4.fc2] 时间: 0.39s | 误差: 28.4878
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...
[layer5.self_attn.k_proj] 时间: 0.16s | 误差: 29111.1797
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...
[layer5.self_attn.v_proj] 时间: 0.11s | 误差: 2831.0850
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...
[layer5.self_attn.q_proj] 时间: 0.10s | 误差: 34245.6328
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...
[layer5.self_attn.out_proj] 时间: 0.10s | 误差: 38.7044
Processing layer 5, component fc1
Pruning with SparseGPT ...
[layer5.fc1] 时间: 0.10s | 误差: 7984.7842
Processing layer 5, component fc2
Pruning with SparseGPT ...
[layer5.fc2] 时间: 0.39s | 误差: 68.5489
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...
[layer6.self_attn.k_proj] 时间: 0.14s | 误差: 31488.2227
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...
[layer6.self_attn.v_proj] 时间: 0.11s | 误差: 3854.9451
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...
[layer6.self_attn.q_proj] 时间: 0.10s | 误差: 33281.5938
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...
[layer6.self_attn.out_proj] 时间: 0.11s | 误差: 49.1255
Processing layer 6, component fc1
Pruning with SparseGPT ...
[layer6.fc1] 时间: 0.10s | 误差: 7930.1035
Processing layer 6, component fc2
Pruning with SparseGPT ...
[layer6.fc2] 时间: 0.38s | 误差: 98.6604
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...
[layer7.self_attn.k_proj] 时间: 0.16s | 误差: 38629.4141
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...
[layer7.self_attn.v_proj] 时间: 0.10s | 误差: 4477.2881
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...
[layer7.self_attn.q_proj] 时间: 0.10s | 误差: 38450.2109
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...
[layer7.self_attn.out_proj] 时间: 0.11s | 误差: 83.3270
Processing layer 7, component fc1
Pruning with SparseGPT ...
[layer7.fc1] 时间: 0.10s | 误差: 10196.3438
Processing layer 7, component fc2
Pruning with SparseGPT ...
[layer7.fc2] 时间: 0.38s | 误差: 134.0841
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...
[layer8.self_attn.k_proj] 时间: 0.15s | 误差: 39485.2266
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...
[layer8.self_attn.v_proj] 时间: 0.10s | 误差: 6357.5234
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...
[layer8.self_attn.q_proj] 时间: 0.09s | 误差: 44017.3594
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...
[layer8.self_attn.out_proj] 时间: 0.10s | 误差: 157.0854
Processing layer 8, component fc1
Pruning with SparseGPT ...
[layer8.fc1] 时间: 0.10s | 误差: 14125.4395
Processing layer 8, component fc2
Pruning with SparseGPT ...
[layer8.fc2] 时间: 0.40s | 误差: 220.6763
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...
[layer9.self_attn.k_proj] 时间: 0.16s | 误差: 46403.6250
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...
[layer9.self_attn.v_proj] 时间: 0.11s | 误差: 7490.8242
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...
[layer9.self_attn.q_proj] 时间: 0.11s | 误差: 50359.3672
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...
[layer9.self_attn.out_proj] 时间: 0.11s | 误差: 274.0133
Processing layer 9, component fc1
Pruning with SparseGPT ...
[layer9.fc1] 时间: 0.11s | 误差: 19375.2852
Processing layer 9, component fc2
Pruning with SparseGPT ...
[layer9.fc2] 时间: 0.38s | 误差: 361.0609
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...
[layer10.self_attn.k_proj] 时间: 0.16s | 误差: 43880.8828
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...
[layer10.self_attn.v_proj] 时间: 0.11s | 误差: 9329.7520
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...
[layer10.self_attn.q_proj] 时间: 0.11s | 误差: 43067.0391
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...
[layer10.self_attn.out_proj] 时间: 0.11s | 误差: 258.3955
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Processing layer 10, component fc1
Pruning with SparseGPT ...
[layer10.fc1] 时间: 0.11s | 误差: 24406.7188
Processing layer 10, component fc2
Pruning with SparseGPT ...
[layer10.fc2] 时间: 0.39s | 误差: 552.2217
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...
[layer11.self_attn.k_proj] 时间: 0.15s | 误差: 43226.0938
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...
[layer11.self_attn.v_proj] 时间: 0.10s | 误差: 11629.4219
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...
[layer11.self_attn.q_proj] 时间: 0.09s | 误差: 46029.1797
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...
[layer11.self_attn.out_proj] 时间: 0.11s | 误差: 457.9461
Processing layer 11, component fc1
Pruning with SparseGPT ...
[layer11.fc1] 时间: 0.10s | 误差: 26915.2812
Processing layer 11, component fc2
Pruning with SparseGPT ...
[layer11.fc2] 时间: 0.39s | 误差: 579.8107

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 0

比特分布:

每层统计:
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 50.00% sparse
Layer model.decoder.layers.0.fc2.weight: 50.00% sparse
Total pruning time: 27.12s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 36.096
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 55.914
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 35.560
