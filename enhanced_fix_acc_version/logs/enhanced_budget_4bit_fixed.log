/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.k_proj] 时间: 5.96s | 误差: 973307.0000
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.v_proj] 时间: 5.75s | 误差: 19683.5273
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.q_proj] 时间: 5.82s | 误差: 768715.8750
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.out_proj] 时间: 5.81s | 误差: 752.2299
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.fc1] 时间: 5.66s | 误差: 745782.6875
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer0.fc2] 时间: 23.20s | 误差: 156073.1250
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.k_proj] 时间: 5.85s | 误差: 418099.5000
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.v_proj] 时间: 5.90s | 误差: 8247.9834
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.q_proj] 时间: 3.43s | 误差: 338754.8750
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.out_proj] 时间: 5.48s | 误差: 232.4495
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.fc1] 时间: 5.71s | 误差: 327290.5625
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer1.fc2] 时间: 23.41s | 误差: 34862.0508
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.k_proj] 时间: 5.74s | 误差: 1815546.0000
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.v_proj] 时间: 5.60s | 误差: 36517.4531
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.q_proj] 时间: 5.69s | 误差: 1641009.6250
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.out_proj] 时间: 5.78s | 误差: 228.8513
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.fc1] 时间: 5.76s | 误差: 182711.5625
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer2.fc2] 时间: 23.11s | 误差: 20626380.0000
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.k_proj] 时间: 5.72s | 误差: 424359.9375
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.v_proj] 时间: 5.76s | 误差: 41587.3594
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.q_proj] 时间: 5.80s | 误差: 398713.3125
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.out_proj] 时间: 5.69s | 误差: 379.9434
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.fc1] 时间: 5.74s | 误差: 97579.7656
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer3.fc2] 时间: 22.97s | 误差: 10473.8555
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.k_proj] 时间: 5.72s | 误差: 641059.2500
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.v_proj] 时间: 5.85s | 误差: 33382.0391
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.q_proj] 时间: 5.67s | 误差: 495375.5000
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.out_proj] 时间: 5.75s | 误差: 542.9382
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.fc1] 时间: 5.84s | 误差: 500875.5000
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer4.fc2] 时间: 22.79s | 误差: 10215.2949
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.k_proj] 时间: 5.46s | 误差: 496168.6562
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.v_proj] 时间: 5.78s | 误差: 25741.9492
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.q_proj] 时间: 5.73s | 误差: 466169.7812
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.out_proj] 时间: 5.81s | 误差: 2082.4475
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.fc1] 时间: 5.86s | 误差: 474383.2188
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer5.fc2] 时间: 14.75s | 误差: 9109.1201
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.k_proj] 时间: 0.28s | 误差: 282002.7188
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.v_proj] 时间: 0.28s | 误差: 19515.3945
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.q_proj] 时间: 0.28s | 误差: 215022.8281
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.out_proj] 时间: 0.28s | 误差: 931.1077
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.fc1] 时间: 0.28s | 误差: 383368.9688
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer6.fc2] 时间: 1.11s | 误差: 9469.5391
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.k_proj] 时间: 0.28s | 误差: 256479.4531
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.v_proj] 时间: 0.28s | 误差: 17668.1523
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.q_proj] 时间: 0.28s | 误差: 198142.4844
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.out_proj] 时间: 0.28s | 误差: 1932.7207
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.fc1] 时间: 0.28s | 误差: 1157326.7500
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer7.fc2] 时间: 1.11s | 误差: 5969.2808
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.k_proj] 时间: 1.73s | 误差: 288345.2188
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.v_proj] 时间: 0.28s | 误差: 25678.7500
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.q_proj] 时间: 0.28s | 误差: 226432.7031
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.out_proj] 时间: 0.28s | 误差: 6252.4136
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.fc1] 时间: 0.28s | 误差: 1329317.1250
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer8.fc2] 时间: 1.11s | 误差: 10321.4336
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.k_proj] 时间: 1.73s | 误差: 359227.0000
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.v_proj] 时间: 0.28s | 误差: 39932.0391
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.q_proj] 时间: 0.28s | 误差: 263539.8125
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.out_proj] 时间: 0.28s | 误差: 3328.3860
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.fc1] 时间: 0.28s | 误差: 104672.9766
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer9.fc2] 时间: 1.11s | 误差: 7749.7559
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.k_proj] 时间: 1.74s | 误差: 342384.2500
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.v_proj] 时间: 0.28s | 误差: 42970.4961
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.q_proj] 时间: 0.28s | 误差: 201778.8750
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.out_proj] 时间: 0.28s | 误差: 16578.2051
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.fc1] 时间: 0.28s | 误差: 90380.6797
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer10.fc2] 时间: 1.11s | 误差: 8464.2168
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.k_proj] 时间: 0.28s | 误差: 222105.4844
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.v_proj] 时间: 0.28s | 误差: 55963.3086
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.q_proj] 时间: 1.72s | 误差: 179643.6875
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.out_proj] 时间: 0.28s | 误差: 105576.7031
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.fc1] 时间: 0.28s | 误差: 253117.4062
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer11.fc2] 时间: 1.11s | 误差: 98699.8750

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  55296 通道 (66.67%)
  8-bit:  27648 通道 (33.33%)

平均比特数: 4.000 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 15.47% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 15.49% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 15.46% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 14.32% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 16.07% sparse
Layer model.decoder.layers.0.fc2.weight: 18.81% sparse
Total pruning time: 332.96s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 10720.458
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 11398.717
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 8046.653
