运行增强版 SparseGPT (Budget方法, 目标8.0bit)...
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.k_proj] 时间: 0.58s | 误差: 2354.4395
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.v_proj] 时间: 0.49s | 误差: 103.1248
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.q_proj] 时间: 0.49s | 误差: 2542.3240
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.self_attn.out_proj] 时间: 0.49s | 误差: 1.1691
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer0.fc1] 时间: 0.50s | 误差: 424.8900
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer0.fc2] 时间: 1.98s | 误差: 6.5404
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.k_proj] 时间: 0.50s | 误差: 1522.6082
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.v_proj] 时间: 0.49s | 误差: 116.3539
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.q_proj] 时间: 0.51s | 误差: 603.5837
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.self_attn.out_proj] 时间: 0.49s | 误差: 0.7393
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer1.fc1] 时间: 0.49s | 误差: 1152.9408
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer1.fc2] 时间: 1.97s | 误差: 1.5552
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.k_proj] 时间: 0.49s | 误差: 2492.5725
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.v_proj] 时间: 0.50s | 误差: 316.0984
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.q_proj] 时间: 0.49s | 误差: 2133.0442
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.self_attn.out_proj] 时间: 0.50s | 误差: 1.7866
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer2.fc1] 时间: 0.49s | 误差: 905.3458
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer2.fc2] 时间: 1.98s | 误差: 0.5247
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.k_proj] 时间: 0.49s | 误差: 2025.6017
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.v_proj] 时间: 0.48s | 误差: 441.2247
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.q_proj] 时间: 0.49s | 误差: 2097.9429
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.self_attn.out_proj] 时间: 0.49s | 误差: 3.0346
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer3.fc1] 时间: 0.49s | 误差: 526.4940
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer3.fc2] 时间: 1.96s | 误差: 0.0000
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.k_proj] 时间: 0.49s | 误差: 4941.3745
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.v_proj] 时间: 0.49s | 误差: 612.4801
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.q_proj] 时间: 0.49s | 误差: 5396.5342
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.self_attn.out_proj] 时间: 2.52s | 误差: 4.4604
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer4.fc1] 时间: 3.65s | 误差: 1456.8507
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer4.fc2] 时间: 14.76s | 误差: 3.4926
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.k_proj] 时间: 3.74s | 误差: 5479.1880
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.v_proj] 时间: 3.70s | 误差: 559.0145
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.q_proj] 时间: 3.69s | 误差: 6595.2583
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.self_attn.out_proj] 时间: 3.74s | 误差: 7.0934
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer5.fc1] 时间: 3.62s | 误差: 1582.3071
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer5.fc2] 时间: 14.71s | 误差: 12.8088
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.k_proj] 时间: 3.78s | 误差: 6049.5742
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.v_proj] 时间: 3.78s | 误差: 775.6509
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.q_proj] 时间: 3.71s | 误差: 6478.8027
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.self_attn.out_proj] 时间: 3.74s | 误差: 9.8614
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer6.fc1] 时间: 3.70s | 误差: 1599.0964
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer6.fc2] 时间: 14.92s | 误差: 19.6889
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.k_proj] 时间: 3.74s | 误差: 7587.6846
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.v_proj] 时间: 3.70s | 误差: 912.7770
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.q_proj] 时间: 3.72s | 误差: 7695.4810
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.self_attn.out_proj] 时间: 3.67s | 误差: 15.2115
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer7.fc1] 时间: 3.72s | 误差: 2066.1245
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer7.fc2] 时间: 14.93s | 误差: 27.2009
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.k_proj] 时间: 3.88s | 误差: 7797.2432
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.v_proj] 时间: 3.70s | 误差: 1294.9961
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.q_proj] 时间: 3.69s | 误差: 8822.0713
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.self_attn.out_proj] 时间: 3.74s | 误差: 27.4981
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer8.fc1] 时间: 3.70s | 误差: 2848.5552
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer8.fc2] 时间: 14.94s | 误差: 45.1891
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.k_proj] 时间: 11.58s | 误差: 9322.6094
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.v_proj] 时间: 20.89s | 误差: 1515.1375
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.q_proj] 时间: 21.04s | 误差: 10138.4990
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.self_attn.out_proj] 时间: 20.85s | 误差: 45.7477
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer9.fc1] 时间: 21.32s | 误差: 3924.6157
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer9.fc2] 时间: 85.48s | 误差: 74.8932
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.k_proj] 时间: 21.43s | 误差: 8884.4609
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.v_proj] 时间: 21.48s | 误差: 1891.6298
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.q_proj] 时间: 21.52s | 误差: 8807.1621
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.self_attn.out_proj] 时间: 21.65s | 误差: 48.2553
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer10.fc1] 时间: 21.06s | 误差: 4965.4033
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer10.fc2] 时间: 85.08s | 误差: 116.7462
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.k_proj] 时间: 21.51s | 误差: 8854.9033
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.v_proj] 时间: 21.34s | 误差: 2362.6797
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.q_proj] 时间: 21.02s | 误差: 9491.4668
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.self_attn.out_proj] 时间: 21.35s | 误差: 77.9000
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 8bit(768通道) | 平均: 8.00 bits
[layer11.fc1] 时间: 21.40s | 误差: 5530.0420
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 8bit(3072通道) | 平均: 8.00 bits
[layer11.fc2] 时间: 84.62s | 误差: 124.6698

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  8-bit:  82944 通道 (100.00%)

平均比特数: 8.000 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 30.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 30.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 30.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 30.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 30.00% sparse
Layer model.decoder.layers.0.fc2.weight: 30.00% sparse
Total pruning time: 749.77s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 27.566
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 42.995
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 29.333
完成时间: 2025年 10月 13日 星期一 02:56:17 CST

