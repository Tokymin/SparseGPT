"""
å¯¹æ¯”åŸºå‡†æ¨¡å‹å’ŒMIé‡åŒ–æ¨¡å‹çš„æ€§èƒ½
"""

import json
import os
import re

def extract_compressed_results(log_file):
    """ä»test_fix.logä¸­æå–å‹ç¼©æ¨¡å‹çš„ç»“æœ"""
    results = {}
    
    if not os.path.exists(log_file):
        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ–‡ä»¶ {log_file}")
        return results
    
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–æ€»æ—¶é—´
    time_match = re.search(r'Total time:\s+([\d.]+)s', content)
    if time_match:
        results['total_time'] = float(time_match.group(1))
    
    # æå–å¹³å‡æ¯”ç‰¹æ•°
    bits_match = re.search(r'å¹³å‡æ¯”ç‰¹æ•°:\s+([\d.]+)\s+bits', content)
    if bits_match:
        results['avg_bits'] = float(bits_match.group(1))
    
    # æå–å„æ•°æ®é›†çš„å›°æƒ‘åº¦
    datasets = {
        'wikitext2': r'Perplexity on wikitext2:\s+([\d.]+)',
        'ptb': r'Perplexity on ptb:\s+([\d.]+)',
        'c4': r'Perplexity on c4:\s+([\d.]+)'
    }
    
    for dataset, pattern in datasets.items():
        match = re.search(pattern, content)
        if match:
            results[dataset] = float(match.group(1))
    
    # æå–æ¯”ç‰¹åˆ†é…ç»Ÿè®¡
    bit_dist_match = re.search(
        r'2-bit:\s+(\d+)\s+é€šé“.*?\n.*?'
        r'3-bit:\s+(\d+)\s+é€šé“.*?\n.*?'
        r'4-bit:\s+(\d+)\s+é€šé“.*?\n.*?'
        r'6-bit:\s+(\d+)\s+é€šé“.*?\n.*?'
        r'8-bit:\s+(\d+)\s+é€šé“',
        content, re.DOTALL
    )
    if bit_dist_match:
        results['bit_distribution'] = {
            '2bit': int(bit_dist_match.group(1)),
            '3bit': int(bit_dist_match.group(2)),
            '4bit': int(bit_dist_match.group(3)),
            '6bit': int(bit_dist_match.group(4)),
            '8bit': int(bit_dist_match.group(5))
        }
    
    return results


def load_baseline_results(json_file):
    """åŠ è½½åŸºå‡†æµ‹è¯•ç»“æœ"""
    if not os.path.exists(json_file):
        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°åŸºå‡†æµ‹è¯•ç»“æœæ–‡ä»¶ {json_file}")
        return None
    
    with open(json_file, 'r') as f:
        return json.load(f)


def print_comparison(baseline, compressed):
    """æ‰“å°å¯¹æ¯”ç»“æœ"""
    
    print("="*100)
    print(" "*35 + "Vicuna-13B æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("="*100)
    print()
    
    # 1. æ¨¡å‹é…ç½®å¯¹æ¯”
    print("ğŸ“Š æ¨¡å‹é…ç½®å¯¹æ¯”")
    print("-"*100)
    print(f"{'é…ç½®é¡¹':<30} {'åŸºå‡†æ¨¡å‹ (FP16)':<30} {'MIé‡åŒ–æ¨¡å‹':<30}")
    print("-"*100)
    print(f"{'ç²¾åº¦':<30} {'16-bit (FP16)':<30} {f'{compressed.get(\"avg_bits\", \"N/A\"):.2f}-bit (å¹³å‡)':<30}")
    print(f"{'ç¨€ç–åº¦':<30} {'0% (dense)':<30} {'50% (sparse)':<30}")
    print(f"{'å‹ç¼©æ–¹æ³•':<30} {'æ— ':<30} {'MIåˆ†ç»„é‡åŒ– + å‰ªæ':<30}")
    print("-"*100)
    print()
    
    # 2. å›°æƒ‘åº¦å¯¹æ¯”
    print("ğŸ“ˆ å›°æƒ‘åº¦ (Perplexity) å¯¹æ¯”")
    print("-"*100)
    print(f"{'æ•°æ®é›†':<20} {'åŸºå‡† (FP16)':<20} {'å‹ç¼©å':<20} {'å˜åŒ–':<20} {'æ€§èƒ½ä¿æŒç‡':<20}")
    print("-"*100)
    
    for dataset in ['wikitext2', 'ptb', 'c4']:
        if baseline and dataset in baseline:
            base_ppl = baseline[dataset]['ppl']
            comp_ppl = compressed.get(dataset, 0)
            
            if comp_ppl > 0:
                change = comp_ppl - base_ppl
                change_pct = (change / base_ppl) * 100
                retention = 100 - abs(change_pct)
                
                # åˆ¤æ–­æ€§èƒ½ç­‰çº§
                if retention >= 95:
                    rating = "â­â­â­â­â­ ä¼˜ç§€"
                elif retention >= 90:
                    rating = "â­â­â­â­ è‰¯å¥½"
                elif retention >= 85:
                    rating = "â­â­â­ ä¸€èˆ¬"
                else:
                    rating = "â­â­ è¾ƒå·®"
                
                print(f"{dataset.upper():<20} {base_ppl:<20.3f} {comp_ppl:<20.3f} "
                      f"{change:+.3f} ({change_pct:+.2f}%){'':<5} {retention:.1f}% {rating}")
            else:
                print(f"{dataset.upper():<20} {base_ppl:<20.3f} {'N/A':<20} {'N/A':<20} {'N/A':<20}")
    
    print("-"*100)
    print()
    
    # 3. å‹ç¼©æ•ˆæœåˆ†æ
    if 'avg_bits' in compressed and 'bit_distribution' in compressed:
        print("ğŸ—œï¸  å‹ç¼©æ•ˆæœåˆ†æ")
        print("-"*100)
        
        avg_bits = compressed['avg_bits']
        bit_dist = compressed['bit_distribution']
        total_channels = sum(bit_dist.values())
        
        # ç†è®ºå‹ç¼©ç‡ (ç›¸å¯¹äºFP16)
        compression_ratio_bits = 16.0 / avg_bits
        
        # è€ƒè™‘ç¨€ç–åº¦çš„å®é™…å‹ç¼©ç‡
        sparsity = 0.5  # 50%ç¨€ç–åº¦
        effective_bits = avg_bits * (1 - sparsity)  # ç¨€ç–æƒé‡ä¸å­˜å‚¨
        compression_ratio_total = 16.0 / effective_bits
        
        print(f"å¹³å‡é‡åŒ–ä½å®½: {avg_bits:.2f} bits")
        print(f"ç›®æ ‡ä½å®½: 4.0 bits")
        print(f"ç¨€ç–åº¦: 50%")
        print()
        print(f"å‹ç¼©ç‡:")
        print(f"  - ä»…é‡åŒ–: {compression_ratio_bits:.2f}x (16bit â†’ {avg_bits:.2f}bit)")
        print(f"  - é‡åŒ–+å‰ªæ: {compression_ratio_total:.2f}x (è€ƒè™‘50%ç¨€ç–åº¦)")
        print()
        print(f"æ¯”ç‰¹åˆ†é…åˆ†å¸ƒ:")
        for bit_level in ['2bit', '3bit', '4bit', '6bit', '8bit']:
            count = bit_dist.get(bit_level, 0)
            pct = (count / total_channels * 100) if total_channels > 0 else 0
            bar_len = int(pct / 2)  # ç¼©æ”¾åˆ°50å­—ç¬¦å®½åº¦
            bar = 'â–ˆ' * bar_len
            print(f"  {bit_level}: {bar:<50} {count:>10} ({pct:>5.2f}%)")
        
        print("-"*100)
        print()
    
    # 4. æ—¶é—´å¼€é”€
    if baseline and compressed.get('total_time'):
        print("â±ï¸  è®¡ç®—å¼€é”€å¯¹æ¯”")
        print("-"*100)
        
        # åŸºå‡†æ¨¡å‹è¯„ä¼°æ—¶é—´ï¼ˆ3ä¸ªæ•°æ®é›†ï¼‰
        base_eval_time = sum(baseline[ds]['time'] for ds in ['wikitext2', 'ptb', 'c4'] if ds in baseline)
        
        # å‹ç¼©æ¨¡å‹æ€»æ—¶é—´ï¼ˆåŒ…å«å‹ç¼©+è¯„ä¼°ï¼‰
        comp_total_time = compressed['total_time']
        
        print(f"åŸºå‡†æ¨¡å‹è¯„ä¼°æ—¶é—´: {base_eval_time:.2f}ç§’ ({base_eval_time/60:.1f}åˆ†é’Ÿ)")
        print(f"å‹ç¼©+è¯„ä¼°æ€»æ—¶é—´: {comp_total_time:.2f}ç§’ ({comp_total_time/60:.1f}åˆ†é’Ÿ)")
        print()
        print(f"æ³¨: å‹ç¼©æ˜¯ä¸€æ¬¡æ€§å¼€é”€ï¼Œå‹ç¼©åçš„æ¨¡å‹æ¨ç†é€Ÿåº¦ä¼šæ›´å¿«")
        print("-"*100)
        print()
    
    # 5. æ€»ä½“è¯„ä»·
    print("ğŸ¯ æ€»ä½“è¯„ä»·")
    print("-"*100)
    
    # è®¡ç®—å¹³å‡æ€§èƒ½ä¿æŒç‡
    if baseline:
        retentions = []
        for dataset in ['wikitext2', 'ptb', 'c4']:
            if dataset in baseline and dataset in compressed:
                base_ppl = baseline[dataset]['ppl']
                comp_ppl = compressed[dataset]
                if comp_ppl > 0:
                    change_pct = abs((comp_ppl - base_ppl) / base_ppl * 100)
                    retention = 100 - change_pct
                    retentions.append(retention)
        
        if retentions:
            avg_retention = sum(retentions) / len(retentions)
            
            print(f"å¹³å‡æ€§èƒ½ä¿æŒç‡: {avg_retention:.1f}%")
            
            if compressed.get('avg_bits'):
                avg_bits = compressed['avg_bits']
                compression_ratio = 16.0 / avg_bits * 2  # è€ƒè™‘50%ç¨€ç–åº¦
                
                print(f"æ€»ä½“å‹ç¼©ç‡: {compression_ratio:.2f}x")
                print()
                
                # è¯„ä»·
                if avg_retention >= 95 and compression_ratio >= 3:
                    rating = "â­â­â­â­â­ ä¼˜ç§€"
                    comment = "åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å®ç°äº†æ˜¾è‘—çš„æ¨¡å‹å‹ç¼©"
                elif avg_retention >= 90 and compression_ratio >= 2:
                    rating = "â­â­â­â­ è‰¯å¥½"
                    comment = "æ€§èƒ½å’Œå‹ç¼©ç‡å–å¾—äº†è¾ƒå¥½å¹³è¡¡"
                elif avg_retention >= 85:
                    rating = "â­â­â­ ä¸€èˆ¬"
                    comment = "æœ‰ä¸€å®šå‹ç¼©æ•ˆæœï¼Œä½†æ€§èƒ½ä¸‹é™æ˜æ˜¾"
                else:
                    rating = "â­â­ éœ€è¦æ”¹è¿›"
                    comment = "æ€§èƒ½ä¸‹é™è¾ƒå¤§ï¼Œéœ€è¦ä¼˜åŒ–å‹ç¼©ç­–ç•¥"
                
                print(f"ç»¼åˆè¯„çº§: {rating}")
                print(f"è¯„ä»·: {comment}")
    
    print("-"*100)
    print()
    
    # 6. æ”¹è¿›å»ºè®®
    if compressed.get('bit_distribution'):
        bit_dist = compressed['bit_distribution']
        total = sum(bit_dist.values())
        pct_8bit = (bit_dist.get('8bit', 0) / total * 100) if total > 0 else 0
        pct_4bit = (bit_dist.get('4bit', 0) / total * 100) if total > 0 else 0
        
        if pct_8bit > 80:
            print("ğŸ’¡ æ”¹è¿›å»ºè®®")
            print("-"*100)
            print(f"âš ï¸  å½“å‰ {pct_8bit:.1f}% çš„é€šé“ä½¿ç”¨ 8-bitï¼Œå‹ç¼©ç‡ä¸è¶³")
            print()
            print("å»ºè®®:")
            print("  1. è°ƒæ•´æ¯”ç‰¹åˆ†é…ç­–ç•¥ï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„é˜ˆå€¼")
            print("  2. å¢åŠ æ ¡å‡†æ ·æœ¬æ•° (16 â†’ 128)")
            print("  3. å¢åŠ åˆ†ç»„æ•° (5 â†’ 10-15)")
            print("  4. ä¿®æ”¹ channel_grouping.py ä¸­çš„æ¯”ç‰¹åˆ†é…é€»è¾‘")
            print()
            print("è¯¦ç»†ä¼˜åŒ–å»ºè®®è¯·æŸ¥çœ‹: æµ‹è¯•ç»“æœåˆ†æ.md")
            print("-"*100)
    
    print()
    print("="*100)


def main():
    # æ–‡ä»¶è·¯å¾„
    baseline_file = "baseline_results.json"
    compressed_log = "test_fix.log"
    
    print("\næ­£åœ¨åŠ è½½æµ‹è¯•ç»“æœ...")
    
    # åŠ è½½ç»“æœ
    baseline = load_baseline_results(baseline_file)
    compressed = extract_compressed_results(compressed_log)
    
    if not baseline:
        print("\nâš ï¸  åŸºå‡†æµ‹è¯•ç»“æœæœªæ‰¾åˆ°!")
        print("è¯·å…ˆè¿è¡Œ: ./test_baseline.sh")
        print()
        return
    
    if not compressed:
        print("\nâš ï¸  å‹ç¼©æ¨¡å‹æµ‹è¯•ç»“æœæœªæ‰¾åˆ°!")
        print("è¯·æ£€æŸ¥ test_fix.log æ–‡ä»¶")
        print()
        return
    
    # æ‰“å°å¯¹æ¯”
    print_comparison(baseline, compressed)
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    comparison = {
        'baseline': baseline,
        'compressed': compressed,
        'timestamp': __import__('datetime').datetime.now().isoformat()
    }
    
    with open('comparison_results.json', 'w') as f:
        json.dump(comparison, f, indent=2)
    
    print("å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: comparison_results.json")
    print()


if __name__ == '__main__':
    main()

