运行增强版 SparseGPT (Budget方法, 目标4.0bit)...
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.k_proj] 时间: 13.21s | 误差: 13602.1074
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.v_proj] 时间: 12.98s | 误差: 533.1898
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.q_proj] 时间: 12.93s | 误差: 13788.3301
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.out_proj] 时间: 12.97s | 误差: 6.2849
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.fc1] 时间: 12.98s | 误差: 2199.3340
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer0.fc2] 时间: 51.97s | 误差: 34.3660
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.k_proj] 时间: 12.97s | 误差: 9456.9277
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.v_proj] 时间: 12.82s | 误差: 624.7369
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.q_proj] 时间: 12.86s | 误差: 3916.2834
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.out_proj] 时间: 12.91s | 误差: 3.9823
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.fc1] 时间: 13.01s | 误差: 6109.9453
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer1.fc2] 时间: 51.85s | 误差: 13.3632
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.k_proj] 时间: 12.95s | 误差: 15455.2334
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.v_proj] 时间: 12.94s | 误差: 1641.6998
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.q_proj] 时间: 12.95s | 误差: 13944.4561
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.out_proj] 时间: 12.93s | 误差: 9.4491
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.fc1] 时间: 13.21s | 误差: 4954.1455
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer2.fc2] 时间: 51.93s | 误差: 9.8810
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.k_proj] 时间: 12.95s | 误差: 14012.7822
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.v_proj] 时间: 13.13s | 误差: 2278.8799
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.q_proj] 时间: 13.15s | 误差: 14031.4805
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.out_proj] 时间: 12.99s | 误差: 16.0174
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.fc1] 时间: 13.02s | 误差: 3019.6965
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer3.fc2] 时间: 51.83s | 误差: 0.4516
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.k_proj] 时间: 13.16s | 误差: 26812.3027
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.v_proj] 时间: 12.29s | 误差: 3107.6069
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.q_proj] 时间: 12.79s | 误差: 28663.3340
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.out_proj] 时间: 12.97s | 误差: 24.2370
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.fc1] 时间: 13.25s | 误差: 7806.0625
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer4.fc2] 时间: 51.62s | 误差: 28.5118
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.k_proj] 时间: 13.02s | 误差: 29111.7090
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.v_proj] 时间: 13.05s | 误差: 2831.0376
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.q_proj] 时间: 12.93s | 误差: 34242.1016
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.out_proj] 时间: 13.00s | 误差: 38.6558
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.fc1] 时间: 12.97s | 误差: 7987.1572
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer5.fc2] 时间: 52.00s | 误差: 68.4077
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.k_proj] 时间: 13.12s | 误差: 31462.5840
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.v_proj] 时间: 13.05s | 误差: 3854.2559
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.q_proj] 时间: 13.01s | 误差: 33278.5234
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.out_proj] 时间: 12.96s | 误差: 49.2530
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.fc1] 时间: 12.95s | 误差: 7926.5576
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer6.fc2] 时间: 51.78s | 误差: 98.5877
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.k_proj] 时间: 12.90s | 误差: 38650.4531
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.v_proj] 时间: 12.79s | 误差: 4478.6221
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.q_proj] 时间: 12.94s | 误差: 38451.0195
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.out_proj] 时间: 12.86s | 误差: 83.6418
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.fc1] 时间: 13.00s | 误差: 10194.2471
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer7.fc2] 时间: 51.78s | 误差: 134.0808
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.k_proj] 时间: 12.88s | 误差: 39452.6406
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.v_proj] 时间: 12.95s | 误差: 6353.2754
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.q_proj] 时间: 13.17s | 误差: 44013.7188
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.out_proj] 时间: 12.90s | 误差: 157.3816
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.fc1] 时间: 13.03s | 误差: 14120.0117
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer8.fc2] 时间: 51.84s | 误差: 220.6047
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.k_proj] 时间: 12.93s | 误差: 46350.3086
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.v_proj] 时间: 13.03s | 误差: 7487.8730
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.q_proj] 时间: 12.93s | 误差: 50324.3711
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.out_proj] 时间: 12.96s | 误差: 273.0558
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.fc1] 时间: 12.78s | 误差: 19360.0469
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer9.fc2] 时间: 51.80s | 误差: 360.5228
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.k_proj] 时间: 13.06s | 误差: 43853.8359
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.v_proj] 时间: 12.96s | 误差: 9329.6875
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.q_proj] 时间: 13.01s | 误差: 43040.7344
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.out_proj] 时间: 13.24s | 误差: 257.7951
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.fc1] 时间: 13.05s | 误差: 24402.1895
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer10.fc2] 时间: 51.77s | 误差: 551.1313
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.k_proj] 时间: 12.98s | 误差: 43191.3359
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.v_proj] 时间: 12.96s | 误差: 11612.2969
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.q_proj] 时间: 12.97s | 误差: 45986.2812
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.out_proj] 时间: 12.97s | 误差: 462.1172
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.fc1] 时间: 13.00s | 误差: 26881.0430
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer11.fc2] 时间: 52.08s | 误差: 577.0457

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  55296 通道 (66.67%)
  8-bit:  27648 通道 (33.33%)

平均比特数: 4.000 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 50.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 50.00% sparse
Layer model.decoder.layers.0.fc2.weight: 50.00% sparse
Total pruning time: 1419.80s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 36.175
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 55.930
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 35.615
完成时间: 2025年 10月 13日 星期一 04:14:44 CST

