运行增强版 SparseGPT (Budget方法, 目标4.0bit)...
/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.k_proj] 时间: 12.09s | 误差: 54305.2070
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.v_proj] 时间: 11.98s | 误差: 1761.9504
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.q_proj] 时间: 12.15s | 误差: 53373.2461
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.self_attn.out_proj] 时间: 12.00s | 误差: 22.5923
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer0.fc1] 时间: 11.90s | 误差: 7312.2974
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer0.fc2] 时间: 47.78s | 误差: 114.5998
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.k_proj] 时间: 11.87s | 误差: 40949.7227
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.v_proj] 时间: 12.21s | 误差: 2109.5366
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.q_proj] 时间: 12.08s | 误差: 18085.5762
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.self_attn.out_proj] 时间: 11.98s | 误差: 15.5549
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer1.fc1] 时间: 11.94s | 误差: 20654.6211
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer1.fc2] 时间: 47.92s | 误差: 47.3815
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.k_proj] 时间: 11.99s | 误差: 59834.0430
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.v_proj] 时间: 11.93s | 误差: 5203.1875
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.q_proj] 时间: 11.95s | 误差: 53439.9727
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.self_attn.out_proj] 时间: 11.95s | 误差: 29.2577
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer2.fc1] 时间: 11.90s | 误差: 17010.6953
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer2.fc2] 时间: 47.74s | 误差: 49.1314
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.k_proj] 时间: 12.01s | 误差: 54145.5312
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.v_proj] 时间: 12.12s | 误差: 6859.5635
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.q_proj] 时间: 11.90s | 误差: 52786.2031
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.self_attn.out_proj] 时间: 11.97s | 误差: 36.6235
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer3.fc1] 时间: 11.95s | 误差: 10655.6367
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer3.fc2] 时间: 47.72s | 误差: 11.7140
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.k_proj] 时间: 12.02s | 误差: 86218.9531
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.v_proj] 时间: 11.88s | 误差: 8938.3906
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.q_proj] 时间: 11.97s | 误差: 91425.9375
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.self_attn.out_proj] 时间: 11.97s | 误差: 68.8792
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer4.fc1] 时间: 11.97s | 误差: 23677.4414
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer4.fc2] 时间: 47.93s | 误差: 92.8092
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.k_proj] 时间: 11.90s | 误差: 90522.4531
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.v_proj] 时间: 11.97s | 误差: 7953.3154
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.q_proj] 时间: 11.85s | 误差: 104168.9688
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.self_attn.out_proj] 时间: 11.89s | 误差: 102.2942
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer5.fc1] 时间: 11.93s | 误差: 22730.8262
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer5.fc2] 时间: 47.92s | 误差: 180.9586
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.k_proj] 时间: 12.04s | 误差: 93744.1562
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.v_proj] 时间: 11.94s | 误差: 10339.7441
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.q_proj] 时间: 11.89s | 误差: 98022.6250
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.self_attn.out_proj] 时间: 11.91s | 误差: 138.2159
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer6.fc1] 时间: 11.97s | 误差: 21625.9141
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer6.fc2] 时间: 47.17s | 误差: 203.2230
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.k_proj] 时间: 12.00s | 误差: 108842.3125
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.v_proj] 时间: 11.97s | 误差: 11554.8955
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.q_proj] 时间: 11.99s | 误差: 107858.9844
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.self_attn.out_proj] 时间: 11.94s | 误差: 191.5641
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer7.fc1] 时间: 12.07s | 误差: 26515.6914
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer7.fc2] 时间: 47.77s | 误差: 196.2748
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.k_proj] 时间: 11.75s | 误差: 106514.7031
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.v_proj] 时间: 12.00s | 误差: 15953.7539
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.q_proj] 时间: 12.01s | 误差: 119033.3047
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.self_attn.out_proj] 时间: 12.00s | 误差: 443.3470
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer8.fc1] 时间: 11.94s | 误差: 35656.1484
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer8.fc2] 时间: 13.73s | 误差: 286.4506
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.k_proj] 时间: 2.32s | 误差: 118748.0859
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.v_proj] 时间: 2.28s | 误差: 18318.9219
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.q_proj] 时间: 2.32s | 误差: 130032.4141
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.self_attn.out_proj] 时间: 2.26s | 误差: 1031.3373
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer9.fc1] 时间: 2.29s | 误差: 47986.7500
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer9.fc2] 时间: 9.20s | 误差: 476.0062
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.k_proj] 时间: 2.38s | 误差: 109371.4766
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.v_proj] 时间: 2.33s | 误差: 22366.1387
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.q_proj] 时间: 2.27s | 误差: 106545.2188
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.self_attn.out_proj] 时间: 2.29s | 误差: 548.2023
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer10.fc1] 时间: 2.27s | 误差: 58881.7344
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer10.fc2] 时间: 9.11s | 误差: 742.8347
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
[layer11.self_attn.k_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.k_proj] 时间: 2.31s | 误差: 104282.7969
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.v_proj] 时间: 2.27s | 误差: 27430.0312
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.q_proj] 时间: 2.27s | 误差: 112272.1406
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.self_attn.out_proj] 时间: 2.29s | 误差: 1759.1594
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(512通道) 8bit(256通道) | 平均: 4.00 bits
[layer11.fc1] 时间: 2.34s | 误差: 56983.5898
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(2048通道) 8bit(1024通道) | 平均: 4.00 bits
[layer11.fc2] 时间: 9.48s | 误差: 821.0006

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  55296 通道 (66.67%)
  8-bit:  27648 通道 (33.33%)

平均比特数: 4.000 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 70.00% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 70.00% sparse
Layer model.decoder.layers.0.fc2.weight: 70.00% sparse
Total pruning time: 1013.18s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 218.549
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 259.005
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 162.843
完成时间: 2025年 10月 13日 星期一 05:46:53 CST

