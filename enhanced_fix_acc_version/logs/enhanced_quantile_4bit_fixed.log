/media/user/data3/toky/CondaEnvs/SparseGPT/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using device: cuda
Starting sequential pruning & quantization ...
Ready for layer-wise processing.
Processing layer 0, component self_attn.k_proj
Pruning with SparseGPT ...

[layer0.self_attn.k_proj] 计算多维度重要性分数...
[layer0.self_attn.k_proj] 分配量化比特数...
[layer0.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.k_proj] 时间: 3.55s | 误差: 503769.2188
Processing layer 0, component self_attn.v_proj
Pruning with SparseGPT ...

[layer0.self_attn.v_proj] 计算多维度重要性分数...
[layer0.self_attn.v_proj] 分配量化比特数...
[layer0.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.v_proj] 时间: 3.43s | 误差: 9969.0469
Processing layer 0, component self_attn.q_proj
Pruning with SparseGPT ...

[layer0.self_attn.q_proj] 计算多维度重要性分数...
[layer0.self_attn.q_proj] 分配量化比特数...
[layer0.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.q_proj] 时间: 3.31s | 误差: 351352.2500
Processing layer 0, component self_attn.out_proj
Pruning with SparseGPT ...

[layer0.self_attn.out_proj] 计算多维度重要性分数...
[layer0.self_attn.out_proj] 分配量化比特数...
[layer0.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.self_attn.out_proj] 时间: 3.36s | 误差: 176.2504
Processing layer 0, component fc1
Pruning with SparseGPT ...

[layer0.fc1] 计算多维度重要性分数...
[layer0.fc1] 分配量化比特数...
[layer0.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer0.fc1] 时间: 3.32s | 误差: 107839.2812
Processing layer 0, component fc2
Pruning with SparseGPT ...

[layer0.fc2] 计算多维度重要性分数...
[layer0.fc2] 分配量化比特数...
[layer0.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer0.fc2] 时间: 13.34s | 误差: 14972.6777
Processing layer 1, component self_attn.k_proj
Pruning with SparseGPT ...

[layer1.self_attn.k_proj] 计算多维度重要性分数...
[layer1.self_attn.k_proj] 分配量化比特数...
[layer1.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.k_proj] 时间: 3.42s | 误差: 98754.5000
Processing layer 1, component self_attn.v_proj
Pruning with SparseGPT ...

[layer1.self_attn.v_proj] 计算多维度重要性分数...
[layer1.self_attn.v_proj] 分配量化比特数...
[layer1.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.v_proj] 时间: 3.31s | 误差: 3030.0974
Processing layer 1, component self_attn.q_proj
Pruning with SparseGPT ...

[layer1.self_attn.q_proj] 计算多维度重要性分数...
[layer1.self_attn.q_proj] 分配量化比特数...
[layer1.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.q_proj] 时间: 3.38s | 误差: 80026.6875
Processing layer 1, component self_attn.out_proj
Pruning with SparseGPT ...

[layer1.self_attn.out_proj] 计算多维度重要性分数...
[layer1.self_attn.out_proj] 分配量化比特数...
[layer1.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.self_attn.out_proj] 时间: 3.43s | 误差: 163.9562
Processing layer 1, component fc1
Pruning with SparseGPT ...

[layer1.fc1] 计算多维度重要性分数...
[layer1.fc1] 分配量化比特数...
[layer1.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer1.fc1] 时间: 3.41s | 误差: 97881.6719
Processing layer 1, component fc2
Pruning with SparseGPT ...

[layer1.fc2] 计算多维度重要性分数...
[layer1.fc2] 分配量化比特数...
[layer1.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer1.fc2] 时间: 13.61s | 误差: 2662.0903
Processing layer 2, component self_attn.k_proj
Pruning with SparseGPT ...

[layer2.self_attn.k_proj] 计算多维度重要性分数...
[layer2.self_attn.k_proj] 分配量化比特数...
[layer2.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.k_proj] 时间: 3.41s | 误差: 130332.1016
Processing layer 2, component self_attn.v_proj
Pruning with SparseGPT ...

[layer2.self_attn.v_proj] 计算多维度重要性分数...
[layer2.self_attn.v_proj] 分配量化比特数...
[layer2.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.v_proj] 时间: 3.40s | 误差: 5062.2539
Processing layer 2, component self_attn.q_proj
Pruning with SparseGPT ...

[layer2.self_attn.q_proj] 计算多维度重要性分数...
[layer2.self_attn.q_proj] 分配量化比特数...
[layer2.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.q_proj] 时间: 3.48s | 误差: 102079.8281
Processing layer 2, component self_attn.out_proj
Pruning with SparseGPT ...

[layer2.self_attn.out_proj] 计算多维度重要性分数...
[layer2.self_attn.out_proj] 分配量化比特数...
[layer2.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.self_attn.out_proj] 时间: 3.41s | 误差: 132.0742
Processing layer 2, component fc1
Pruning with SparseGPT ...

[layer2.fc1] 计算多维度重要性分数...
[layer2.fc1] 分配量化比特数...
[layer2.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer2.fc1] 时间: 3.40s | 误差: 55287.0273
Processing layer 2, component fc2
Pruning with SparseGPT ...

[layer2.fc2] 计算多维度重要性分数...
[layer2.fc2] 分配量化比特数...
[layer2.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer2.fc2] 时间: 13.53s | 误差: 24188.9141
Processing layer 3, component self_attn.k_proj
Pruning with SparseGPT ...

[layer3.self_attn.k_proj] 计算多维度重要性分数...
[layer3.self_attn.k_proj] 分配量化比特数...
[layer3.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.k_proj] 时间: 3.43s | 误差: 84338.2656
Processing layer 3, component self_attn.v_proj
Pruning with SparseGPT ...

[layer3.self_attn.v_proj] 计算多维度重要性分数...
[layer3.self_attn.v_proj] 分配量化比特数...
[layer3.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.v_proj] 时间: 3.32s | 误差: 6124.8770
Processing layer 3, component self_attn.q_proj
Pruning with SparseGPT ...

[layer3.self_attn.q_proj] 计算多维度重要性分数...
[layer3.self_attn.q_proj] 分配量化比特数...
[layer3.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.q_proj] 时间: 3.37s | 误差: 74442.1250
Processing layer 3, component self_attn.out_proj
Pruning with SparseGPT ...

[layer3.self_attn.out_proj] 计算多维度重要性分数...
[layer3.self_attn.out_proj] 分配量化比特数...
[layer3.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.self_attn.out_proj] 时间: 3.36s | 误差: 216.2182
Processing layer 3, component fc1
Pruning with SparseGPT ...

[layer3.fc1] 计算多维度重要性分数...
[layer3.fc1] 分配量化比特数...
[layer3.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer3.fc1] 时间: 3.46s | 误差: 35277.4062
Processing layer 3, component fc2
Pruning with SparseGPT ...

[layer3.fc2] 计算多维度重要性分数...
[layer3.fc2] 分配量化比特数...
[layer3.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer3.fc2] 时间: 13.43s | 误差: 1872.9084
Processing layer 4, component self_attn.k_proj
Pruning with SparseGPT ...

[layer4.self_attn.k_proj] 计算多维度重要性分数...
[layer4.self_attn.k_proj] 分配量化比特数...
[layer4.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.k_proj] 时间: 3.37s | 误差: 158907.1406
Processing layer 4, component self_attn.v_proj
Pruning with SparseGPT ...

[layer4.self_attn.v_proj] 计算多维度重要性分数...
[layer4.self_attn.v_proj] 分配量化比特数...
[layer4.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.v_proj] 时间: 3.43s | 误差: 9215.0488
Processing layer 4, component self_attn.q_proj
Pruning with SparseGPT ...

[layer4.self_attn.q_proj] 计算多维度重要性分数...
[layer4.self_attn.q_proj] 分配量化比特数...
[layer4.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.q_proj] 时间: 3.48s | 误差: 137394.3125
Processing layer 4, component self_attn.out_proj
Pruning with SparseGPT ...

[layer4.self_attn.out_proj] 计算多维度重要性分数...
[layer4.self_attn.out_proj] 分配量化比特数...
[layer4.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.self_attn.out_proj] 时间: 3.42s | 误差: 819.3433
Processing layer 4, component fc1
Pruning with SparseGPT ...

[layer4.fc1] 计算多维度重要性分数...
[layer4.fc1] 分配量化比特数...
[layer4.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer4.fc1] 时间: 3.34s | 误差: 90354.4062
Processing layer 4, component fc2
Pruning with SparseGPT ...

[layer4.fc2] 计算多维度重要性分数...
[layer4.fc2] 分配量化比特数...
[layer4.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer4.fc2] 时间: 13.57s | 误差: 3842.5811
Processing layer 5, component self_attn.k_proj
Pruning with SparseGPT ...

[layer5.self_attn.k_proj] 计算多维度重要性分数...
[layer5.self_attn.k_proj] 分配量化比特数...
[layer5.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.k_proj] 时间: 3.42s | 误差: 117038.8125
Processing layer 5, component self_attn.v_proj
Pruning with SparseGPT ...

[layer5.self_attn.v_proj] 计算多维度重要性分数...
[layer5.self_attn.v_proj] 分配量化比特数...
[layer5.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.v_proj] 时间: 3.35s | 误差: 5038.8501
Processing layer 5, component self_attn.q_proj
Pruning with SparseGPT ...

[layer5.self_attn.q_proj] 计算多维度重要性分数...
[layer5.self_attn.q_proj] 分配量化比特数...
[layer5.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.q_proj] 时间: 3.47s | 误差: 93867.4141
Processing layer 5, component self_attn.out_proj
Pruning with SparseGPT ...

[layer5.self_attn.out_proj] 计算多维度重要性分数...
[layer5.self_attn.out_proj] 分配量化比特数...
[layer5.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.self_attn.out_proj] 时间: 3.37s | 误差: 275.7777
Processing layer 5, component fc1
Pruning with SparseGPT ...

[layer5.fc1] 计算多维度重要性分数...
[layer5.fc1] 分配量化比特数...
[layer5.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer5.fc1] 时间: 3.23s | 误差: 81571.7188
Processing layer 5, component fc2
Pruning with SparseGPT ...

[layer5.fc2] 计算多维度重要性分数...
[layer5.fc2] 分配量化比特数...
[layer5.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer5.fc2] 时间: 13.46s | 误差: 2393.1013
Processing layer 6, component self_attn.k_proj
Pruning with SparseGPT ...

[layer6.self_attn.k_proj] 计算多维度重要性分数...
[layer6.self_attn.k_proj] 分配量化比特数...
[layer6.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.k_proj] 时间: 3.32s | 误差: 114931.6484
Processing layer 6, component self_attn.v_proj
Pruning with SparseGPT ...

[layer6.self_attn.v_proj] 计算多维度重要性分数...
[layer6.self_attn.v_proj] 分配量化比特数...
[layer6.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.v_proj] 时间: 3.40s | 误差: 7412.5713
Processing layer 6, component self_attn.q_proj
Pruning with SparseGPT ...

[layer6.self_attn.q_proj] 计算多维度重要性分数...
[layer6.self_attn.q_proj] 分配量化比特数...
[layer6.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.q_proj] 时间: 3.32s | 误差: 97638.2188
Processing layer 6, component self_attn.out_proj
Pruning with SparseGPT ...

[layer6.self_attn.out_proj] 计算多维度重要性分数...
[layer6.self_attn.out_proj] 分配量化比特数...
[layer6.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.self_attn.out_proj] 时间: 3.31s | 误差: 1090.7086
Processing layer 6, component fc1
Pruning with SparseGPT ...

[layer6.fc1] 计算多维度重要性分数...
[layer6.fc1] 分配量化比特数...
[layer6.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer6.fc1] 时间: 3.32s | 误差: 85129.9922
Processing layer 6, component fc2
Pruning with SparseGPT ...

[layer6.fc2] 计算多维度重要性分数...
[layer6.fc2] 分配量化比特数...
[layer6.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer6.fc2] 时间: 13.51s | 误差: 2584.7495
Processing layer 7, component self_attn.k_proj
Pruning with SparseGPT ...

[layer7.self_attn.k_proj] 计算多维度重要性分数...
[layer7.self_attn.k_proj] 分配量化比特数...
[layer7.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.k_proj] 时间: 3.39s | 误差: 184445.5625
Processing layer 7, component self_attn.v_proj
Pruning with SparseGPT ...

[layer7.self_attn.v_proj] 计算多维度重要性分数...
[layer7.self_attn.v_proj] 分配量化比特数...
[layer7.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.v_proj] 时间: 3.44s | 误差: 12083.6309
Processing layer 7, component self_attn.q_proj
Pruning with SparseGPT ...

[layer7.self_attn.q_proj] 计算多维度重要性分数...
[layer7.self_attn.q_proj] 分配量化比特数...
[layer7.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.q_proj] 时间: 3.31s | 误差: 153345.8750
Processing layer 7, component self_attn.out_proj
Pruning with SparseGPT ...

[layer7.self_attn.out_proj] 计算多维度重要性分数...
[layer7.self_attn.out_proj] 分配量化比特数...
[layer7.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.self_attn.out_proj] 时间: 3.38s | 误差: 1093.0579
Processing layer 7, component fc1
Pruning with SparseGPT ...

[layer7.fc1] 计算多维度重要性分数...
[layer7.fc1] 分配量化比特数...
[layer7.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer7.fc1] 时间: 3.43s | 误差: 88323.4688
Processing layer 7, component fc2
Pruning with SparseGPT ...

[layer7.fc2] 计算多维度重要性分数...
[layer7.fc2] 分配量化比特数...
[layer7.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer7.fc2] 时间: 13.55s | 误差: 3454.8291
Processing layer 8, component self_attn.k_proj
Pruning with SparseGPT ...

[layer8.self_attn.k_proj] 计算多维度重要性分数...
[layer8.self_attn.k_proj] 分配量化比特数...
[layer8.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.k_proj] 时间: 3.39s | 误差: 171842.4688
Processing layer 8, component self_attn.v_proj
Pruning with SparseGPT ...

[layer8.self_attn.v_proj] 计算多维度重要性分数...
[layer8.self_attn.v_proj] 分配量化比特数...
[layer8.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.v_proj] 时间: 3.41s | 误差: 13937.7119
Processing layer 8, component self_attn.q_proj
Pruning with SparseGPT ...

[layer8.self_attn.q_proj] 计算多维度重要性分数...
[layer8.self_attn.q_proj] 分配量化比特数...
[layer8.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.q_proj] 时间: 3.41s | 误差: 141182.4688
Processing layer 8, component self_attn.out_proj
Pruning with SparseGPT ...

[layer8.self_attn.out_proj] 计算多维度重要性分数...
[layer8.self_attn.out_proj] 分配量化比特数...
[layer8.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.self_attn.out_proj] 时间: 3.39s | 误差: 2304.2412
Processing layer 8, component fc1
Pruning with SparseGPT ...

[layer8.fc1] 计算多维度重要性分数...
[layer8.fc1] 分配量化比特数...
[layer8.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer8.fc1] 时间: 3.44s | 误差: 113254.3047
Processing layer 8, component fc2
Pruning with SparseGPT ...

[layer8.fc2] 计算多维度重要性分数...
[layer8.fc2] 分配量化比特数...
[layer8.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer8.fc2] 时间: 13.57s | 误差: 5620.9492
Processing layer 9, component self_attn.k_proj
Pruning with SparseGPT ...

[layer9.self_attn.k_proj] 计算多维度重要性分数...
[layer9.self_attn.k_proj] 分配量化比特数...
[layer9.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.k_proj] 时间: 3.37s | 误差: 198987.6250
Processing layer 9, component self_attn.v_proj
Pruning with SparseGPT ...

[layer9.self_attn.v_proj] 计算多维度重要性分数...
[layer9.self_attn.v_proj] 分配量化比特数...
[layer9.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.v_proj] 时间: 3.43s | 误差: 15428.0039
Processing layer 9, component self_attn.q_proj
Pruning with SparseGPT ...

[layer9.self_attn.q_proj] 计算多维度重要性分数...
[layer9.self_attn.q_proj] 分配量化比特数...
[layer9.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.q_proj] 时间: 3.37s | 误差: 163895.7188
Processing layer 9, component self_attn.out_proj
Pruning with SparseGPT ...

[layer9.self_attn.out_proj] 计算多维度重要性分数...
[layer9.self_attn.out_proj] 分配量化比特数...
[layer9.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.self_attn.out_proj] 时间: 3.34s | 误差: 4681.0063
Processing layer 9, component fc1
Pruning with SparseGPT ...

[layer9.fc1] 计算多维度重要性分数...
[layer9.fc1] 分配量化比特数...
[layer9.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer9.fc1] 时间: 3.33s | 误差: 143552.9219
Processing layer 9, component fc2
Pruning with SparseGPT ...

[layer9.fc2] 计算多维度重要性分数...
[layer9.fc2] 分配量化比特数...
[layer9.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer9.fc2] 时间: 13.48s | 误差: 5297.5312
Processing layer 10, component self_attn.k_proj
Pruning with SparseGPT ...

[layer10.self_attn.k_proj] 计算多维度重要性分数...
[layer10.self_attn.k_proj] 分配量化比特数...
[layer10.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.k_proj] 时间: 3.40s | 误差: 207038.1562
Processing layer 10, component self_attn.v_proj
Pruning with SparseGPT ...

[layer10.self_attn.v_proj] 计算多维度重要性分数...
[layer10.self_attn.v_proj] 分配量化比特数...
[layer10.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.v_proj] 时间: 3.36s | 误差: 20425.0742
Processing layer 10, component self_attn.q_proj
Pruning with SparseGPT ...

[layer10.self_attn.q_proj] 计算多维度重要性分数...
[layer10.self_attn.q_proj] 分配量化比特数...
[layer10.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.q_proj] 时间: 3.42s | 误差: 171984.1562
Processing layer 10, component self_attn.out_proj
Pruning with SparseGPT ...

[layer10.self_attn.out_proj] 计算多维度重要性分数...
[layer10.self_attn.out_proj] 分配量化比特数...
[layer10.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.self_attn.out_proj] 时间: 3.42s | 误差: 6562.7617
Processing layer 10, component fc1
Pruning with SparseGPT ...

[layer10.fc1] 计算多维度重要性分数...
[layer10.fc1] 分配量化比特数...
[layer10.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer10.fc1] 时间: 3.32s | 误差: 110643.5781
Processing layer 10, component fc2
Pruning with SparseGPT ...

[layer10.fc2] 计算多维度重要性分数...
[layer10.fc2] 分配量化比特数...
[layer10.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer10.fc2] 时间: 13.33s | 误差: 5532.0010
Processing layer 11, component self_attn.k_proj
Pruning with SparseGPT ...

[layer11.self_attn.k_proj] 计算多维度重要性分数...
[layer11.self_attn.k_proj] 分配量化比特数...
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
Reusing dataset ptb_text_only (/home/user/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)
[layer11.self_attn.k_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.k_proj] 时间: 3.35s | 误差: 169439.0156
Processing layer 11, component self_attn.v_proj
Pruning with SparseGPT ...

[layer11.self_attn.v_proj] 计算多维度重要性分数...
[layer11.self_attn.v_proj] 分配量化比特数...
[layer11.self_attn.v_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.v_proj] 时间: 3.31s | 误差: 33965.0391
Processing layer 11, component self_attn.q_proj
Pruning with SparseGPT ...

[layer11.self_attn.q_proj] 计算多维度重要性分数...
[layer11.self_attn.q_proj] 分配量化比特数...
[layer11.self_attn.q_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.q_proj] 时间: 3.30s | 误差: 145995.5000
Processing layer 11, component self_attn.out_proj
Pruning with SparseGPT ...

[layer11.self_attn.out_proj] 计算多维度重要性分数...
[layer11.self_attn.out_proj] 分配量化比特数...
[layer11.self_attn.out_proj] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.self_attn.out_proj] 时间: 3.41s | 误差: 8547.6055
Processing layer 11, component fc1
Pruning with SparseGPT ...

[layer11.fc1] 计算多维度重要性分数...
[layer11.fc1] 分配量化比特数...
[layer11.fc1] 比特分布: 2bit(154通道) 3bit(153通道) 4bit(154通道) 6bit(153通道) 8bit(154通道) | 平均: 4.60 bits
[layer11.fc1] 时间: 3.39s | 误差: 195692.1719
Processing layer 11, component fc2
Pruning with SparseGPT ...

[layer11.fc2] 计算多维度重要性分数...
[layer11.fc2] 分配量化比特数...
[layer11.fc2] 比特分布: 2bit(615通道) 3bit(614通道) 4bit(614通道) 6bit(614通道) 8bit(615通道) | 平均: 4.60 bits
[layer11.fc2] 时间: 13.38s | 误差: 128346.6250

================================================================================

============================================================
量化统计摘要 (Quantization Statistics Summary)
============================================================

总通道数: 82944

比特分布:
  2-bit:  16620 通道 (20.04%)
  3-bit:  16548 通道 (19.95%)
  4-bit:  16608 通道 (20.02%)
  6-bit:  16548 通道 (19.95%)
  8-bit:  16620 通道 (20.04%)

平均比特数: 4.600 bits
============================================================

================================================================================

Layer model.decoder.embed_tokens.weight: 0.00% sparse
Layer model.decoder.embed_positions.weight: 0.05% sparse
Layer model.decoder.final_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.self_attn.k_proj.weight: 35.08% sparse
Layer model.decoder.layers.0.self_attn.v_proj.weight: 36.11% sparse
Layer model.decoder.layers.0.self_attn.q_proj.weight: 35.53% sparse
Layer model.decoder.layers.0.self_attn.out_proj.weight: 35.53% sparse
Layer model.decoder.layers.0.self_attn_layer_norm.weight: 0.00% sparse
Layer model.decoder.layers.0.fc1.weight: 33.73% sparse
Layer model.decoder.layers.0.fc2.weight: 40.50% sparse
Total pruning time: 381.16s
Evaluating on wikitext2
Evaluating on wikitext2 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on wikitext2: 6059.029
Evaluating on ptb
Evaluating on ptb ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on ptb: 5178.101
Evaluating on c4
Evaluating on c4 ...
Evaluating layer 0
Evaluating layer 1
Evaluating layer 2
Evaluating layer 3
Evaluating layer 4
Evaluating layer 5
Evaluating layer 6
Evaluating layer 7
Evaluating layer 8
Evaluating layer 9
Evaluating layer 10
Evaluating layer 11
Perplexity on c4: 3804.103
